{"cells":[{"cell_type":"markdown","source":["### 모델을 향상시키는 방법\n","1. 모델 바꾸기\n","2. 데이터 수정 및 추가\n","3. hyperparameter tuning\n","\n","- 2번이 가장 중요"],"metadata":{"id":"s1CW0iFXJBbW"}},{"cell_type":"markdown","metadata":{"id":"8dnckgcpbdYT"},"source":["## Hyperparameter Turning\n","- 모델이 스스로 학습하지 않는 값은 사람이 지정(learning rate, 모델 크기, optimizer 등)\n","- 마지막 0.01%를 쥐어짜야 할 때 도전해볼만함\n","- 가장 기본적인 방법\n","  - grid search: 일정한 범위를 정해 값을 자름, 차례대로 학습 수행한 후 가장 좋은 성능을 내는 것 찾음\n","  - random search: random하게 학습 수행한 후 가 장 좋은 것 찾기\n","- 최근에는 베이지안 기반 기법들이 주도 (BOHB)"]},{"cell_type":"markdown","source":["## Ray\n","- multi-node multi processing 지원 모듈\n","- ML/DL 병렬 처리 모듈의 표준\n","- Hyperparameter search를 위한 다양한 모듈 제공"],"metadata":{"id":"tO_-ltJ4KpF5"}},{"cell_type":"code","source":["data_dir = os.path.abspath(\"./data\")\n","load_data(data_dir)\n","# config에 search space 지정\n","config = {\n","    \"l1\": tune.sample_from(lambda _: 2 ** np.random.randint(2, 9)),\n","    \"l2\": tune.sample_from(lambda _: 2 ** np.random.randint(2, 9)),\n","    \"lr\": tune.loguniform(1e-4, 1e-1),\n","\"batch_size\": tune.choice([2, 4, 8, 16])\n","}\n","\n","# 학습 스케줄링 알고리즘 지정\n","scheduler = ASHAScheduler(\n","    metric=\"loss\", mode=\"min\", max_t=max_num_epochs, grace_period=1, reduction_factor=2)\n","reporter = CLIReporter(\n","    metric_columns=[\"loss\", \"accuracy\", \"training_iteration\"])\n","\n","# 병렬 처리 양식으로 학습 시행\n","result = tune.run( #tune.run: 여러개의 cpu에 분산시켜줌\n","    partial(train_cifar, data_dir=data_dir),\n","    resources_per_trial={\"cpu\": 2, \"gpu\": gpus_per_trial},\n","    config=config, num_samples=num_samples,\n","    scheduler=scheduler,\n","    progress_reporter=reporter)"],"metadata":{"id":"vhjNTCR3LNtJ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Ray-tune for Hyperparameter Tuning"],"metadata":{"id":"lQ_NKQ-VLQ7q"}},{"cell_type":"code","execution_count":1,"metadata":{"id":"ot5y7LaCverD","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1679016687777,"user_tz":-540,"elapsed":18160,"user":{"displayName":"이윤표","userId":"15778647441739081017"}},"outputId":"29db6e71-b0d9-41e1-fa46-565c7c2de253"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting ray\n","  Downloading ray-2.3.0-cp39-cp39-manylinux2014_x86_64.whl (58.6 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.6/58.6 MB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: grpcio>=1.32.0 in /usr/local/lib/python3.9/dist-packages (from ray) (1.51.3)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from ray) (3.9.1)\n","Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.9/dist-packages (from ray) (8.1.3)\n","Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in /usr/local/lib/python3.9/dist-packages (from ray) (1.0.5)\n","Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from ray) (2.25.1)\n","Collecting virtualenv>=20.0.24\n","  Downloading virtualenv-20.21.0-py3-none-any.whl (8.7 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.7/8.7 MB\u001b[0m \u001b[31m74.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: attrs in /usr/local/lib/python3.9/dist-packages (from ray) (22.2.0)\n","Requirement already satisfied: jsonschema in /usr/local/lib/python3.9/dist-packages (from ray) (4.3.3)\n","Requirement already satisfied: numpy>=1.19.3 in /usr/local/lib/python3.9/dist-packages (from ray) (1.22.4)\n","Collecting frozenlist\n","  Downloading frozenlist-1.3.3-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (158 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m158.8/158.8 KB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pyyaml in /usr/local/lib/python3.9/dist-packages (from ray) (6.0)\n","Requirement already satisfied: protobuf!=3.19.5,>=3.15.3 in /usr/local/lib/python3.9/dist-packages (from ray) (3.19.6)\n","Collecting aiosignal\n","  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n","Requirement already satisfied: platformdirs<4,>=2.4 in /usr/local/lib/python3.9/dist-packages (from virtualenv>=20.0.24->ray) (3.1.1)\n","Collecting distlib<1,>=0.3.6\n","  Downloading distlib-0.3.6-py2.py3-none-any.whl (468 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m468.5/468.5 KB\u001b[0m \u001b[31m14.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.9/dist-packages (from jsonschema->ray) (0.19.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->ray) (2022.12.7)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->ray) (1.26.15)\n","Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.9/dist-packages (from requests->ray) (4.0.0)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->ray) (2.10)\n","Installing collected packages: distlib, virtualenv, frozenlist, aiosignal, ray\n","Successfully installed aiosignal-1.3.1 distlib-0.3.6 frozenlist-1.3.3 ray-2.3.0 virtualenv-20.21.0\n"]}],"source":["! pip install ray "]},{"cell_type":"code","execution_count":2,"metadata":{"id":"hbnXPWknqV4H","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1679016692662,"user_tz":-540,"elapsed":4896,"user":{"displayName":"이윤표","userId":"15778647441739081017"}},"outputId":"f79ece1c-6b84-41cc-922f-968a84574164"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting tensorboardX\n","  Downloading tensorboardX-2.6-py2.py3-none-any.whl (114 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.5/114.5 KB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.9/dist-packages (from tensorboardX) (23.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from tensorboardX) (1.22.4)\n","Requirement already satisfied: protobuf<4,>=3.8.0 in /usr/local/lib/python3.9/dist-packages (from tensorboardX) (3.19.6)\n","Installing collected packages: tensorboardX\n","Successfully installed tensorboardX-2.6\n"]}],"source":["!pip install tensorboardX"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"SqfrQN2Q3nbh","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1679016709022,"user_tz":-540,"elapsed":16363,"user":{"displayName":"이윤표","userId":"15778647441739081017"}},"outputId":"352f2844-fa6f-48cd-f7a8-46fa7620d6b8"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting wandb\n","  Downloading wandb-0.14.0-py3-none-any.whl (2.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m62.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting setproctitle\n","  Downloading setproctitle-1.3.2-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\n","Collecting appdirs>=1.4.3\n","  Downloading appdirs-1.4.4-py2.py3-none-any.whl (9.6 kB)\n","Collecting sentry-sdk>=1.0.0\n","  Downloading sentry_sdk-1.17.0-py2.py3-none-any.whl (189 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m189.1/189.1 KB\u001b[0m \u001b[31m14.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: PyYAML in /usr/local/lib/python3.9/dist-packages (from wandb) (6.0)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from wandb) (4.5.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.9/dist-packages (from wandb) (63.4.3)\n","Collecting docker-pycreds>=0.4.0\n","  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n","Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.9/dist-packages (from wandb) (5.4.8)\n","Collecting pathtools\n","  Downloading pathtools-0.1.2.tar.gz (11 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: Click!=8.0.0,>=7.0 in /usr/local/lib/python3.9/dist-packages (from wandb) (8.1.3)\n","Requirement already satisfied: protobuf!=4.21.0,<5,>=3.15.0 in /usr/local/lib/python3.9/dist-packages (from wandb) (3.19.6)\n","Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from wandb) (2.25.1)\n","Collecting GitPython!=3.1.29,>=1.0.0\n","  Downloading GitPython-3.1.31-py3-none-any.whl (184 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m184.3/184.3 KB\u001b[0m \u001b[31m24.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.9/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.15.0)\n","Collecting gitdb<5,>=4.0.1\n","  Downloading gitdb-4.0.10-py3-none-any.whl (62 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 KB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.0.0->wandb) (2022.12.7)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.0.0->wandb) (1.26.15)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.0.0->wandb) (2.10)\n","Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.0.0->wandb) (4.0.0)\n","Collecting smmap<6,>=3.0.1\n","  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n","Building wheels for collected packages: pathtools\n","  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pathtools: filename=pathtools-0.1.2-py3-none-any.whl size=8807 sha256=be3b681fc82bac0aa34159022ccd50f29a3772e6ed9eec48a70c313d3a0b6f01\n","  Stored in directory: /root/.cache/pip/wheels/b7/0a/67/ada2a22079218c75a88361c0782855cc72aebc4d18d0289d05\n","Successfully built pathtools\n","Installing collected packages: pathtools, appdirs, smmap, setproctitle, sentry-sdk, docker-pycreds, gitdb, GitPython, wandb\n","Successfully installed GitPython-3.1.31 appdirs-1.4.4 docker-pycreds-0.4.0 gitdb-4.0.10 pathtools-0.1.2 sentry-sdk-1.17.0 setproctitle-1.3.2 smmap-5.0.0 wandb-0.14.0\n"]}],"source":["!pip install wandb"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"p6v4ORGFvVaI","executionInfo":{"status":"ok","timestamp":1679016714718,"user_tz":-540,"elapsed":5699,"user":{"displayName":"이윤표","userId":"15778647441739081017"}}},"outputs":[],"source":["from functools import partial\n","import numpy as np\n","import os\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","from torch.utils.data import random_split\n","import torchvision\n","import torchvision.transforms as transforms\n","from ray import tune\n","from ray.tune import CLIReporter\n","from ray.tune.schedulers import ASHAScheduler\n","\n","import wandb"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"JK3lcOwElxdF","executionInfo":{"status":"ok","timestamp":1679016714719,"user_tz":-540,"elapsed":5,"user":{"displayName":"이윤표","userId":"15778647441739081017"}}},"outputs":[],"source":["def load_data(data_dir=\"./data\"):\n","    transform = transforms.Compose([\n","        transforms.ToTensor(),\n","        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n","    ])\n","\n","    trainset = torchvision.datasets.CIFAR10(\n","        root=data_dir, train=True, download=True, transform=transform)\n","\n","    testset = torchvision.datasets.CIFAR10(\n","        root=data_dir, train=False, download=True, transform=transform)\n","\n","    return trainset, testset\n"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"FAg2V_8ely9p","executionInfo":{"status":"ok","timestamp":1679016764640,"user_tz":-540,"elapsed":736,"user":{"displayName":"이윤표","userId":"15778647441739081017"}}},"outputs":[],"source":["class Net(nn.Module): \n","    def __init__(self, l1=120, l2=84):\n","        super(Net, self).__init__()\n","        self.conv1 = nn.Conv2d(3, 6, 5)\n","        self.pool = nn.MaxPool2d(2, 2)\n","        self.conv2 = nn.Conv2d(6, 16, 5)\n","        self.fc1 = nn.Linear(16 * 5 * 5, l1)\n","        self.fc2 = nn.Linear(l1, l2) #마지막 layer 2개\n","        self.fc3 = nn.Linear(l2, 10)\n","\n","    def forward(self, x):\n","        x = self.pool(F.relu(self.conv1(x)))\n","        x = self.pool(F.relu(self.conv2(x)))\n","        x = x.view(-1, 16 * 5 * 5)\n","        x = F.relu(self.fc1(x))\n","        x = F.relu(self.fc2(x))\n","        x = self.fc3(x)\n","        return x"]},{"cell_type":"code","execution_count":11,"metadata":{"id":"DopzqPSkowWo","executionInfo":{"status":"ok","timestamp":1679017219988,"user_tz":-540,"elapsed":8,"user":{"displayName":"이윤표","userId":"15778647441739081017"}}},"outputs":[],"source":["# 하나의 함수로 표현되야지만 lay가 불러올 수 있음\n","def train_cifar(config, checkpoint_dir=None, data_dir=None):\n","    net = Net(config[\"l1\"], config[\"l2\"])\n","\n","    device = \"cpu\"\n","    if torch.cuda.is_available():\n","        device = \"cuda:0\"\n","        if torch.cuda.device_count() > 1:\n","            net = nn.DataParallel(net)\n","    net.to(device)\n","\n","    # entropy 설정\n","    criterion = nn.CrossEntropyLoss()\n","    optimizer = optim.SGD(net.parameters(), lr=config[\"lr\"], momentum=0.9)\n","\n","    if checkpoint_dir:\n","        model_state, optimizer_state = torch.load(\n","            os.path.join(checkpoint_dir, \"checkpoint\"))\n","        net.load_state_dict(model_state)\n","        optimizer.load_state_dict(optimizer_state)\n","\n","    trainset, testset = load_data(data_dir)\n","\n","    test_abs = int(len(trainset) * 0.8)\n","    train_subset, val_subset = random_split(\n","        trainset, [test_abs, len(trainset) - test_abs])\n","\n","    trainloader = torch.utils.data.DataLoader(\n","        train_subset,\n","        batch_size=int(config[\"batch_size\"]),\n","        shuffle=True,\n","        num_workers=8)\n","    valloader = torch.utils.data.DataLoader(\n","        val_subset,\n","        batch_size=int(config[\"batch_size\"]),\n","        shuffle=True,\n","        num_workers=8)\n","    wandb.init(project='Ray tuning hyperparameter', entity='imsmile2000')\n","    wandb.watch(net)\n","\n","    for epoch in range(10):  # loop over the dataset multiple times\n","        running_loss = 0.0\n","        epoch_steps = 0\n","        for i, data in enumerate(trainloader, 0):\n","            # get the inputs; data is a list of [inputs, labels]\n","            inputs, labels = data\n","            inputs, labels = inputs.to(device), labels.to(device)\n","\n","            # zero the parameter gradients\n","            optimizer.zero_grad()\n","\n","            # forward + backward + optimize\n","            outputs = net(inputs)\n","            loss = criterion(outputs, labels)\n","            loss.backward()\n","            optimizer.step()\n","\n","            # print statistics\n","            running_loss += loss.item()\n","            epoch_steps += 1\n","            if i % 2000 == 1999:  # print every 2000 mini-batches\n","                print(\"[%d, %5d] loss: %.3f\" % (epoch + 1, i + 1,\n","                                                running_loss / epoch_steps))\n","                running_loss = 0.0\n","\n","        # Validation loss\n","        val_loss = 0.0\n","        val_steps = 0\n","        total = 0\n","        correct = 0\n","        for i, data in enumerate(valloader, 0):\n","            with torch.no_grad():\n","                inputs, labels = data\n","                inputs, labels = inputs.to(device), labels.to(device)\n","\n","                outputs = net(inputs)\n","                _, predicted = torch.max(outputs.data, 1)\n","                total += labels.size(0)\n","                correct += (predicted == labels).sum().item()\n","\n","                loss = criterion(outputs, labels)\n","                val_loss += loss.cpu().numpy()\n","                val_steps += 1\n","\n","        wandb.log({\"val_loss\": val_loss})\n","        wandb.log({\"loss\": loss})\n","\n","        with tune.checkpoint_dir(epoch) as checkpoint_dir:\n","            path = os.path.join(checkpoint_dir, \"checkpoint\")\n","            torch.save((net.state_dict(), optimizer.state_dict()), path)\n","\n","        tune.report(loss=(val_loss / val_steps), accuracy=correct / total)\n","    print(\"Finished Training\")"]},{"cell_type":"code","execution_count":12,"metadata":{"id":"BSzH6czJpX3n","executionInfo":{"status":"ok","timestamp":1679017225190,"user_tz":-540,"elapsed":2,"user":{"displayName":"이윤표","userId":"15778647441739081017"}}},"outputs":[],"source":["def test_accuracy(net, device=\"cpu\"):\n","    trainset, testset = load_data()\n","\n","    testloader = torch.utils.data.DataLoader(\n","        testset, batch_size=4, shuffle=False, num_workers=2)\n","\n","    correct = 0\n","    total = 0\n","    with torch.no_grad():\n","        for data in testloader:\n","            images, labels = data\n","            images, labels = images.to(device), labels.to(device)\n","            outputs = net(images)\n","            _, predicted = torch.max(outputs.data, 1)\n","            total += labels.size(0)\n","            correct += (predicted == labels).sum().item()\n","\n","    return correct / total"]},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"j5BkGGECo5ZS","outputId":"a12fbcaf-e161-41aa-8e52-540fca3907da","executionInfo":{"status":"error","timestamp":1679017464890,"user_tz":-540,"elapsed":239165,"user":{"displayName":"이윤표","userId":"15778647441739081017"}}},"outputs":[{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mimsmile2000\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"]},{"output_type":"stream","name":"stdout","text":["Files already downloaded and verified\n","Files already downloaded and verified\n","== Status ==\n","Current time: 2023-03-17 01:40:28 (running for 00:00:00.11)\n","Memory usage on this node: 3.1/12.7 GiB \n","Using AsyncHyperBand: num_stopped=0\n","Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: None\n","Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.39 GiB heap, 0.0/3.69 GiB objects\n","Result logdir: /root/ray_results/train_cifar_2023-03-17_01-40-28\n","Number of trials: 10/10 (9 PENDING, 1 RUNNING)\n","+-------------------------+----------+------------------+--------------+------+------+-------------+\n","| Trial name              | status   | loc              |   batch_size |   l1 |   l2 |          lr |\n","|-------------------------+----------+------------------+--------------+------+------+-------------|\n","| train_cifar_b22a4_00000 | RUNNING  | 172.28.0.12:4162 |           16 |   32 |   32 | 0.000414851 |\n","| train_cifar_b22a4_00001 | PENDING  |                  |            8 |   16 |   32 | 0.0520736   |\n","| train_cifar_b22a4_00002 | PENDING  |                  |            4 |   32 |    8 | 0.00498188  |\n","| train_cifar_b22a4_00003 | PENDING  |                  |           16 |    8 |  128 | 0.00841198  |\n","| train_cifar_b22a4_00004 | PENDING  |                  |            2 |  128 |    8 | 0.0115033   |\n","| train_cifar_b22a4_00005 | PENDING  |                  |           16 |  256 |   64 | 0.000892888 |\n","| train_cifar_b22a4_00006 | PENDING  |                  |            4 |   32 |  256 | 0.0251675   |\n","| train_cifar_b22a4_00007 | PENDING  |                  |           16 |  256 |   64 | 0.000238698 |\n","| train_cifar_b22a4_00008 | PENDING  |                  |            2 |  128 |  256 | 0.0198986   |\n","| train_cifar_b22a4_00009 | PENDING  |                  |           16 |  128 |   64 | 0.000264479 |\n","+-------------------------+----------+------------------+--------------+------+------+-------------+\n","\n","\n","\u001b[2m\u001b[36m(func pid=4162)\u001b[0m Files already downloaded and verified\n","\u001b[2m\u001b[36m(func pid=4162)\u001b[0m Files already downloaded and verified\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[2m\u001b[36m(func pid=4162)\u001b[0m /usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","\u001b[2m\u001b[36m(func pid=4162)\u001b[0m   warnings.warn(_create_warning_msg(\n","\u001b[2m\u001b[36m(func pid=4162)\u001b[0m wandb: Currently logged in as: imsmile2000. Use `wandb login --relogin` to force relogin\n","\u001b[2m\u001b[36m(func pid=4162)\u001b[0m wandb: Tracking run with wandb version 0.14.0\n","\u001b[2m\u001b[36m(func pid=4162)\u001b[0m wandb: Run data is saved locally in /root/ray_results/train_cifar_2023-03-17_01-40-28/train_cifar_b22a4_00000_0_batch_size=16,l1=32,l2=32,lr=0.0004_2023-03-17_01-40-28/wandb/run-20230317_014033-x34n97a8\n","\u001b[2m\u001b[36m(func pid=4162)\u001b[0m wandb: Run `wandb offline` to turn off syncing.\n","\u001b[2m\u001b[36m(func pid=4162)\u001b[0m wandb: Syncing run worthy-blaze-1\n","\u001b[2m\u001b[36m(func pid=4162)\u001b[0m wandb: ⭐️ View project at https://wandb.ai/imsmile2000/Ray%20tuning%20hyperparameter\n","\u001b[2m\u001b[36m(func pid=4162)\u001b[0m wandb: 🚀 View run at https://wandb.ai/imsmile2000/Ray%20tuning%20hyperparameter/runs/x34n97a8\n","\u001b[2m\u001b[36m(func pid=4162)\u001b[0m /usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","\u001b[2m\u001b[36m(func pid=4162)\u001b[0m   warnings.warn(_create_warning_msg(\n"]},{"output_type":"stream","name":"stdout","text":["== Status ==\n","Current time: 2023-03-17 01:40:36 (running for 00:00:08.09)\n","Memory usage on this node: 3.7/12.7 GiB \n","Using AsyncHyperBand: num_stopped=0\n","Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: None\n","Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.39 GiB heap, 0.0/3.69 GiB objects\n","Result logdir: /root/ray_results/train_cifar_2023-03-17_01-40-28\n","Number of trials: 10/10 (9 PENDING, 1 RUNNING)\n","+-------------------------+----------+------------------+--------------+------+------+-------------+\n","| Trial name              | status   | loc              |   batch_size |   l1 |   l2 |          lr |\n","|-------------------------+----------+------------------+--------------+------+------+-------------|\n","| train_cifar_b22a4_00000 | RUNNING  | 172.28.0.12:4162 |           16 |   32 |   32 | 0.000414851 |\n","| train_cifar_b22a4_00001 | PENDING  |                  |            8 |   16 |   32 | 0.0520736   |\n","| train_cifar_b22a4_00002 | PENDING  |                  |            4 |   32 |    8 | 0.00498188  |\n","| train_cifar_b22a4_00003 | PENDING  |                  |           16 |    8 |  128 | 0.00841198  |\n","| train_cifar_b22a4_00004 | PENDING  |                  |            2 |  128 |    8 | 0.0115033   |\n","| train_cifar_b22a4_00005 | PENDING  |                  |           16 |  256 |   64 | 0.000892888 |\n","| train_cifar_b22a4_00006 | PENDING  |                  |            4 |   32 |  256 | 0.0251675   |\n","| train_cifar_b22a4_00007 | PENDING  |                  |           16 |  256 |   64 | 0.000238698 |\n","| train_cifar_b22a4_00008 | PENDING  |                  |            2 |  128 |  256 | 0.0198986   |\n","| train_cifar_b22a4_00009 | PENDING  |                  |           16 |  128 |   64 | 0.000264479 |\n","+-------------------------+----------+------------------+--------------+------+------+-------------+\n","\n","\n","== Status ==\n","Current time: 2023-03-17 01:40:41 (running for 00:00:13.11)\n","Memory usage on this node: 3.7/12.7 GiB \n","Using AsyncHyperBand: num_stopped=0\n","Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: None\n","Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.39 GiB heap, 0.0/3.69 GiB objects\n","Result logdir: /root/ray_results/train_cifar_2023-03-17_01-40-28\n","Number of trials: 10/10 (9 PENDING, 1 RUNNING)\n","+-------------------------+----------+------------------+--------------+------+------+-------------+\n","| Trial name              | status   | loc              |   batch_size |   l1 |   l2 |          lr |\n","|-------------------------+----------+------------------+--------------+------+------+-------------|\n","| train_cifar_b22a4_00000 | RUNNING  | 172.28.0.12:4162 |           16 |   32 |   32 | 0.000414851 |\n","| train_cifar_b22a4_00001 | PENDING  |                  |            8 |   16 |   32 | 0.0520736   |\n","| train_cifar_b22a4_00002 | PENDING  |                  |            4 |   32 |    8 | 0.00498188  |\n","| train_cifar_b22a4_00003 | PENDING  |                  |           16 |    8 |  128 | 0.00841198  |\n","| train_cifar_b22a4_00004 | PENDING  |                  |            2 |  128 |    8 | 0.0115033   |\n","| train_cifar_b22a4_00005 | PENDING  |                  |           16 |  256 |   64 | 0.000892888 |\n","| train_cifar_b22a4_00006 | PENDING  |                  |            4 |   32 |  256 | 0.0251675   |\n","| train_cifar_b22a4_00007 | PENDING  |                  |           16 |  256 |   64 | 0.000238698 |\n","| train_cifar_b22a4_00008 | PENDING  |                  |            2 |  128 |  256 | 0.0198986   |\n","| train_cifar_b22a4_00009 | PENDING  |                  |           16 |  128 |   64 | 0.000264479 |\n","+-------------------------+----------+------------------+--------------+------+------+-------------+\n","\n","\n","== Status ==\n","Current time: 2023-03-17 01:40:46 (running for 00:00:18.12)\n","Memory usage on this node: 3.7/12.7 GiB \n","Using AsyncHyperBand: num_stopped=0\n","Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: None\n","Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.39 GiB heap, 0.0/3.69 GiB objects\n","Result logdir: /root/ray_results/train_cifar_2023-03-17_01-40-28\n","Number of trials: 10/10 (9 PENDING, 1 RUNNING)\n","+-------------------------+----------+------------------+--------------+------+------+-------------+\n","| Trial name              | status   | loc              |   batch_size |   l1 |   l2 |          lr |\n","|-------------------------+----------+------------------+--------------+------+------+-------------|\n","| train_cifar_b22a4_00000 | RUNNING  | 172.28.0.12:4162 |           16 |   32 |   32 | 0.000414851 |\n","| train_cifar_b22a4_00001 | PENDING  |                  |            8 |   16 |   32 | 0.0520736   |\n","| train_cifar_b22a4_00002 | PENDING  |                  |            4 |   32 |    8 | 0.00498188  |\n","| train_cifar_b22a4_00003 | PENDING  |                  |           16 |    8 |  128 | 0.00841198  |\n","| train_cifar_b22a4_00004 | PENDING  |                  |            2 |  128 |    8 | 0.0115033   |\n","| train_cifar_b22a4_00005 | PENDING  |                  |           16 |  256 |   64 | 0.000892888 |\n","| train_cifar_b22a4_00006 | PENDING  |                  |            4 |   32 |  256 | 0.0251675   |\n","| train_cifar_b22a4_00007 | PENDING  |                  |           16 |  256 |   64 | 0.000238698 |\n","| train_cifar_b22a4_00008 | PENDING  |                  |            2 |  128 |  256 | 0.0198986   |\n","| train_cifar_b22a4_00009 | PENDING  |                  |           16 |  128 |   64 | 0.000264479 |\n","+-------------------------+----------+------------------+--------------+------+------+-------------+\n","\n","\n","== Status ==\n","Current time: 2023-03-17 01:40:51 (running for 00:00:23.13)\n","Memory usage on this node: 3.7/12.7 GiB \n","Using AsyncHyperBand: num_stopped=0\n","Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: None\n","Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.39 GiB heap, 0.0/3.69 GiB objects\n","Result logdir: /root/ray_results/train_cifar_2023-03-17_01-40-28\n","Number of trials: 10/10 (9 PENDING, 1 RUNNING)\n","+-------------------------+----------+------------------+--------------+------+------+-------------+\n","| Trial name              | status   | loc              |   batch_size |   l1 |   l2 |          lr |\n","|-------------------------+----------+------------------+--------------+------+------+-------------|\n","| train_cifar_b22a4_00000 | RUNNING  | 172.28.0.12:4162 |           16 |   32 |   32 | 0.000414851 |\n","| train_cifar_b22a4_00001 | PENDING  |                  |            8 |   16 |   32 | 0.0520736   |\n","| train_cifar_b22a4_00002 | PENDING  |                  |            4 |   32 |    8 | 0.00498188  |\n","| train_cifar_b22a4_00003 | PENDING  |                  |           16 |    8 |  128 | 0.00841198  |\n","| train_cifar_b22a4_00004 | PENDING  |                  |            2 |  128 |    8 | 0.0115033   |\n","| train_cifar_b22a4_00005 | PENDING  |                  |           16 |  256 |   64 | 0.000892888 |\n","| train_cifar_b22a4_00006 | PENDING  |                  |            4 |   32 |  256 | 0.0251675   |\n","| train_cifar_b22a4_00007 | PENDING  |                  |           16 |  256 |   64 | 0.000238698 |\n","| train_cifar_b22a4_00008 | PENDING  |                  |            2 |  128 |  256 | 0.0198986   |\n","| train_cifar_b22a4_00009 | PENDING  |                  |           16 |  128 |   64 | 0.000264479 |\n","+-------------------------+----------+------------------+--------------+------+------+-------------+\n","\n","\n","\u001b[2m\u001b[36m(func pid=4162)\u001b[0m [1,  2000] loss: 2.303\n","== Status ==\n","Current time: 2023-03-17 01:40:56 (running for 00:00:28.14)\n","Memory usage on this node: 3.7/12.7 GiB \n","Using AsyncHyperBand: num_stopped=0\n","Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: None\n","Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.39 GiB heap, 0.0/3.69 GiB objects\n","Result logdir: /root/ray_results/train_cifar_2023-03-17_01-40-28\n","Number of trials: 10/10 (9 PENDING, 1 RUNNING)\n","+-------------------------+----------+------------------+--------------+------+------+-------------+\n","| Trial name              | status   | loc              |   batch_size |   l1 |   l2 |          lr |\n","|-------------------------+----------+------------------+--------------+------+------+-------------|\n","| train_cifar_b22a4_00000 | RUNNING  | 172.28.0.12:4162 |           16 |   32 |   32 | 0.000414851 |\n","| train_cifar_b22a4_00001 | PENDING  |                  |            8 |   16 |   32 | 0.0520736   |\n","| train_cifar_b22a4_00002 | PENDING  |                  |            4 |   32 |    8 | 0.00498188  |\n","| train_cifar_b22a4_00003 | PENDING  |                  |           16 |    8 |  128 | 0.00841198  |\n","| train_cifar_b22a4_00004 | PENDING  |                  |            2 |  128 |    8 | 0.0115033   |\n","| train_cifar_b22a4_00005 | PENDING  |                  |           16 |  256 |   64 | 0.000892888 |\n","| train_cifar_b22a4_00006 | PENDING  |                  |            4 |   32 |  256 | 0.0251675   |\n","| train_cifar_b22a4_00007 | PENDING  |                  |           16 |  256 |   64 | 0.000238698 |\n","| train_cifar_b22a4_00008 | PENDING  |                  |            2 |  128 |  256 | 0.0198986   |\n","| train_cifar_b22a4_00009 | PENDING  |                  |           16 |  128 |   64 | 0.000264479 |\n","+-------------------------+----------+------------------+--------------+------+------+-------------+\n","\n","\n","== Status ==\n","Current time: 2023-03-17 01:41:01 (running for 00:00:33.15)\n","Memory usage on this node: 3.7/12.7 GiB \n","Using AsyncHyperBand: num_stopped=0\n","Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: None\n","Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.39 GiB heap, 0.0/3.69 GiB objects\n","Result logdir: /root/ray_results/train_cifar_2023-03-17_01-40-28\n","Number of trials: 10/10 (9 PENDING, 1 RUNNING)\n","+-------------------------+----------+------------------+--------------+------+------+-------------+\n","| Trial name              | status   | loc              |   batch_size |   l1 |   l2 |          lr |\n","|-------------------------+----------+------------------+--------------+------+------+-------------|\n","| train_cifar_b22a4_00000 | RUNNING  | 172.28.0.12:4162 |           16 |   32 |   32 | 0.000414851 |\n","| train_cifar_b22a4_00001 | PENDING  |                  |            8 |   16 |   32 | 0.0520736   |\n","| train_cifar_b22a4_00002 | PENDING  |                  |            4 |   32 |    8 | 0.00498188  |\n","| train_cifar_b22a4_00003 | PENDING  |                  |           16 |    8 |  128 | 0.00841198  |\n","| train_cifar_b22a4_00004 | PENDING  |                  |            2 |  128 |    8 | 0.0115033   |\n","| train_cifar_b22a4_00005 | PENDING  |                  |           16 |  256 |   64 | 0.000892888 |\n","| train_cifar_b22a4_00006 | PENDING  |                  |            4 |   32 |  256 | 0.0251675   |\n","| train_cifar_b22a4_00007 | PENDING  |                  |           16 |  256 |   64 | 0.000238698 |\n","| train_cifar_b22a4_00008 | PENDING  |                  |            2 |  128 |  256 | 0.0198986   |\n","| train_cifar_b22a4_00009 | PENDING  |                  |           16 |  128 |   64 | 0.000264479 |\n","+-------------------------+----------+------------------+--------------+------+------+-------------+\n","\n","\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["<div class=\"trialProgress\">\n","  <h3>Trial Progress</h3>\n","  <table>\n","<thead>\n","<tr><th>Trial name             </th><th style=\"text-align: right;\">  accuracy</th><th>date               </th><th>done  </th><th>episodes_total  </th><th>experiment_id                   </th><th>hostname    </th><th style=\"text-align: right;\">  iterations_since_restore</th><th style=\"text-align: right;\">   loss</th><th>node_ip    </th><th style=\"text-align: right;\">  pid</th><th>should_checkpoint  </th><th style=\"text-align: right;\">  time_since_restore</th><th style=\"text-align: right;\">  time_this_iter_s</th><th style=\"text-align: right;\">  time_total_s</th><th style=\"text-align: right;\">  timestamp</th><th style=\"text-align: right;\">  timesteps_since_restore</th><th>timesteps_total  </th><th style=\"text-align: right;\">  training_iteration</th><th>trial_id   </th><th style=\"text-align: right;\">  warmup_time</th></tr>\n","</thead>\n","<tbody>\n","<tr><td>train_cifar_b22a4_00000</td><td style=\"text-align: right;\">    0.4578</td><td>2023-03-17_01-43-59</td><td>False </td><td>                </td><td>c8a5c53c684b4164822861b71abb449a</td><td>b5c83dd34c70</td><td style=\"text-align: right;\">                         6</td><td style=\"text-align: right;\">1.49463</td><td>172.28.0.12</td><td style=\"text-align: right;\"> 4162</td><td>True               </td><td style=\"text-align: right;\">             208.379</td><td style=\"text-align: right;\">           31.8757</td><td style=\"text-align: right;\">       208.379</td><td style=\"text-align: right;\"> 1679017439</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                   6</td><td>b22a4_00000</td><td style=\"text-align: right;\">   0.00377369</td></tr>\n","</tbody>\n","</table>\n","</div>\n","<style>\n",".trialProgress {\n","  display: flex;\n","  flex-direction: column;\n","  color: var(--jp-ui-font-color1);\n","}\n",".trialProgress h3 {\n","  font-weight: bold;\n","}\n",".trialProgress td {\n","  white-space: nowrap;\n","}\n","</style>\n"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["== Status ==\n","Current time: 2023-03-17 01:41:09 (running for 00:00:40.76)\n","Memory usage on this node: 3.7/12.7 GiB \n","Using AsyncHyperBand: num_stopped=0\n","Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: -2.299063328170776\n","Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.39 GiB heap, 0.0/3.69 GiB objects\n","Result logdir: /root/ray_results/train_cifar_2023-03-17_01-40-28\n","Number of trials: 10/10 (9 PENDING, 1 RUNNING)\n","+-------------------------+----------+------------------+--------------+------+------+-------------+---------+------------+----------------------+\n","| Trial name              | status   | loc              |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n","|-------------------------+----------+------------------+--------------+------+------+-------------+---------+------------+----------------------|\n","| train_cifar_b22a4_00000 | RUNNING  | 172.28.0.12:4162 |           16 |   32 |   32 | 0.000414851 | 2.29906 |     0.1482 |                    1 |\n","| train_cifar_b22a4_00001 | PENDING  |                  |            8 |   16 |   32 | 0.0520736   |         |            |                      |\n","| train_cifar_b22a4_00002 | PENDING  |                  |            4 |   32 |    8 | 0.00498188  |         |            |                      |\n","| train_cifar_b22a4_00003 | PENDING  |                  |           16 |    8 |  128 | 0.00841198  |         |            |                      |\n","| train_cifar_b22a4_00004 | PENDING  |                  |            2 |  128 |    8 | 0.0115033   |         |            |                      |\n","| train_cifar_b22a4_00005 | PENDING  |                  |           16 |  256 |   64 | 0.000892888 |         |            |                      |\n","| train_cifar_b22a4_00006 | PENDING  |                  |            4 |   32 |  256 | 0.0251675   |         |            |                      |\n","| train_cifar_b22a4_00007 | PENDING  |                  |           16 |  256 |   64 | 0.000238698 |         |            |                      |\n","| train_cifar_b22a4_00008 | PENDING  |                  |            2 |  128 |  256 | 0.0198986   |         |            |                      |\n","| train_cifar_b22a4_00009 | PENDING  |                  |           16 |  128 |   64 | 0.000264479 |         |            |                      |\n","+-------------------------+----------+------------------+--------------+------+------+-------------+---------+------------+----------------------+\n","\n","\n","== Status ==\n","Current time: 2023-03-17 01:41:14 (running for 00:00:45.79)\n","Memory usage on this node: 3.7/12.7 GiB \n","Using AsyncHyperBand: num_stopped=0\n","Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: -2.299063328170776\n","Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.39 GiB heap, 0.0/3.69 GiB objects\n","Result logdir: /root/ray_results/train_cifar_2023-03-17_01-40-28\n","Number of trials: 10/10 (9 PENDING, 1 RUNNING)\n","+-------------------------+----------+------------------+--------------+------+------+-------------+---------+------------+----------------------+\n","| Trial name              | status   | loc              |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n","|-------------------------+----------+------------------+--------------+------+------+-------------+---------+------------+----------------------|\n","| train_cifar_b22a4_00000 | RUNNING  | 172.28.0.12:4162 |           16 |   32 |   32 | 0.000414851 | 2.29906 |     0.1482 |                    1 |\n","| train_cifar_b22a4_00001 | PENDING  |                  |            8 |   16 |   32 | 0.0520736   |         |            |                      |\n","| train_cifar_b22a4_00002 | PENDING  |                  |            4 |   32 |    8 | 0.00498188  |         |            |                      |\n","| train_cifar_b22a4_00003 | PENDING  |                  |           16 |    8 |  128 | 0.00841198  |         |            |                      |\n","| train_cifar_b22a4_00004 | PENDING  |                  |            2 |  128 |    8 | 0.0115033   |         |            |                      |\n","| train_cifar_b22a4_00005 | PENDING  |                  |           16 |  256 |   64 | 0.000892888 |         |            |                      |\n","| train_cifar_b22a4_00006 | PENDING  |                  |            4 |   32 |  256 | 0.0251675   |         |            |                      |\n","| train_cifar_b22a4_00007 | PENDING  |                  |           16 |  256 |   64 | 0.000238698 |         |            |                      |\n","| train_cifar_b22a4_00008 | PENDING  |                  |            2 |  128 |  256 | 0.0198986   |         |            |                      |\n","| train_cifar_b22a4_00009 | PENDING  |                  |           16 |  128 |   64 | 0.000264479 |         |            |                      |\n","+-------------------------+----------+------------------+--------------+------+------+-------------+---------+------------+----------------------+\n","\n","\n","== Status ==\n","Current time: 2023-03-17 01:41:19 (running for 00:00:50.80)\n","Memory usage on this node: 3.7/12.7 GiB \n","Using AsyncHyperBand: num_stopped=0\n","Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: -2.299063328170776\n","Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.39 GiB heap, 0.0/3.69 GiB objects\n","Result logdir: /root/ray_results/train_cifar_2023-03-17_01-40-28\n","Number of trials: 10/10 (9 PENDING, 1 RUNNING)\n","+-------------------------+----------+------------------+--------------+------+------+-------------+---------+------------+----------------------+\n","| Trial name              | status   | loc              |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n","|-------------------------+----------+------------------+--------------+------+------+-------------+---------+------------+----------------------|\n","| train_cifar_b22a4_00000 | RUNNING  | 172.28.0.12:4162 |           16 |   32 |   32 | 0.000414851 | 2.29906 |     0.1482 |                    1 |\n","| train_cifar_b22a4_00001 | PENDING  |                  |            8 |   16 |   32 | 0.0520736   |         |            |                      |\n","| train_cifar_b22a4_00002 | PENDING  |                  |            4 |   32 |    8 | 0.00498188  |         |            |                      |\n","| train_cifar_b22a4_00003 | PENDING  |                  |           16 |    8 |  128 | 0.00841198  |         |            |                      |\n","| train_cifar_b22a4_00004 | PENDING  |                  |            2 |  128 |    8 | 0.0115033   |         |            |                      |\n","| train_cifar_b22a4_00005 | PENDING  |                  |           16 |  256 |   64 | 0.000892888 |         |            |                      |\n","| train_cifar_b22a4_00006 | PENDING  |                  |            4 |   32 |  256 | 0.0251675   |         |            |                      |\n","| train_cifar_b22a4_00007 | PENDING  |                  |           16 |  256 |   64 | 0.000238698 |         |            |                      |\n","| train_cifar_b22a4_00008 | PENDING  |                  |            2 |  128 |  256 | 0.0198986   |         |            |                      |\n","| train_cifar_b22a4_00009 | PENDING  |                  |           16 |  128 |   64 | 0.000264479 |         |            |                      |\n","+-------------------------+----------+------------------+--------------+------+------+-------------+---------+------------+----------------------+\n","\n","\n","== Status ==\n","Current time: 2023-03-17 01:41:24 (running for 00:00:55.81)\n","Memory usage on this node: 3.7/12.7 GiB \n","Using AsyncHyperBand: num_stopped=0\n","Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: -2.299063328170776\n","Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.39 GiB heap, 0.0/3.69 GiB objects\n","Result logdir: /root/ray_results/train_cifar_2023-03-17_01-40-28\n","Number of trials: 10/10 (9 PENDING, 1 RUNNING)\n","+-------------------------+----------+------------------+--------------+------+------+-------------+---------+------------+----------------------+\n","| Trial name              | status   | loc              |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n","|-------------------------+----------+------------------+--------------+------+------+-------------+---------+------------+----------------------|\n","| train_cifar_b22a4_00000 | RUNNING  | 172.28.0.12:4162 |           16 |   32 |   32 | 0.000414851 | 2.29906 |     0.1482 |                    1 |\n","| train_cifar_b22a4_00001 | PENDING  |                  |            8 |   16 |   32 | 0.0520736   |         |            |                      |\n","| train_cifar_b22a4_00002 | PENDING  |                  |            4 |   32 |    8 | 0.00498188  |         |            |                      |\n","| train_cifar_b22a4_00003 | PENDING  |                  |           16 |    8 |  128 | 0.00841198  |         |            |                      |\n","| train_cifar_b22a4_00004 | PENDING  |                  |            2 |  128 |    8 | 0.0115033   |         |            |                      |\n","| train_cifar_b22a4_00005 | PENDING  |                  |           16 |  256 |   64 | 0.000892888 |         |            |                      |\n","| train_cifar_b22a4_00006 | PENDING  |                  |            4 |   32 |  256 | 0.0251675   |         |            |                      |\n","| train_cifar_b22a4_00007 | PENDING  |                  |           16 |  256 |   64 | 0.000238698 |         |            |                      |\n","| train_cifar_b22a4_00008 | PENDING  |                  |            2 |  128 |  256 | 0.0198986   |         |            |                      |\n","| train_cifar_b22a4_00009 | PENDING  |                  |           16 |  128 |   64 | 0.000264479 |         |            |                      |\n","+-------------------------+----------+------------------+--------------+------+------+-------------+---------+------------+----------------------+\n","\n","\n","\u001b[2m\u001b[36m(func pid=4162)\u001b[0m [2,  2000] loss: 2.276\n","== Status ==\n","Current time: 2023-03-17 01:41:29 (running for 00:01:00.82)\n","Memory usage on this node: 3.7/12.7 GiB \n","Using AsyncHyperBand: num_stopped=0\n","Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: -2.299063328170776\n","Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.39 GiB heap, 0.0/3.69 GiB objects\n","Result logdir: /root/ray_results/train_cifar_2023-03-17_01-40-28\n","Number of trials: 10/10 (9 PENDING, 1 RUNNING)\n","+-------------------------+----------+------------------+--------------+------+------+-------------+---------+------------+----------------------+\n","| Trial name              | status   | loc              |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n","|-------------------------+----------+------------------+--------------+------+------+-------------+---------+------------+----------------------|\n","| train_cifar_b22a4_00000 | RUNNING  | 172.28.0.12:4162 |           16 |   32 |   32 | 0.000414851 | 2.29906 |     0.1482 |                    1 |\n","| train_cifar_b22a4_00001 | PENDING  |                  |            8 |   16 |   32 | 0.0520736   |         |            |                      |\n","| train_cifar_b22a4_00002 | PENDING  |                  |            4 |   32 |    8 | 0.00498188  |         |            |                      |\n","| train_cifar_b22a4_00003 | PENDING  |                  |           16 |    8 |  128 | 0.00841198  |         |            |                      |\n","| train_cifar_b22a4_00004 | PENDING  |                  |            2 |  128 |    8 | 0.0115033   |         |            |                      |\n","| train_cifar_b22a4_00005 | PENDING  |                  |           16 |  256 |   64 | 0.000892888 |         |            |                      |\n","| train_cifar_b22a4_00006 | PENDING  |                  |            4 |   32 |  256 | 0.0251675   |         |            |                      |\n","| train_cifar_b22a4_00007 | PENDING  |                  |           16 |  256 |   64 | 0.000238698 |         |            |                      |\n","| train_cifar_b22a4_00008 | PENDING  |                  |            2 |  128 |  256 | 0.0198986   |         |            |                      |\n","| train_cifar_b22a4_00009 | PENDING  |                  |           16 |  128 |   64 | 0.000264479 |         |            |                      |\n","+-------------------------+----------+------------------+--------------+------+------+-------------+---------+------------+----------------------+\n","\n","\n","== Status ==\n","Current time: 2023-03-17 01:41:34 (running for 00:01:05.84)\n","Memory usage on this node: 3.7/12.7 GiB \n","Using AsyncHyperBand: num_stopped=0\n","Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: -2.299063328170776\n","Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.39 GiB heap, 0.0/3.69 GiB objects\n","Result logdir: /root/ray_results/train_cifar_2023-03-17_01-40-28\n","Number of trials: 10/10 (9 PENDING, 1 RUNNING)\n","+-------------------------+----------+------------------+--------------+------+------+-------------+---------+------------+----------------------+\n","| Trial name              | status   | loc              |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n","|-------------------------+----------+------------------+--------------+------+------+-------------+---------+------------+----------------------|\n","| train_cifar_b22a4_00000 | RUNNING  | 172.28.0.12:4162 |           16 |   32 |   32 | 0.000414851 | 2.29906 |     0.1482 |                    1 |\n","| train_cifar_b22a4_00001 | PENDING  |                  |            8 |   16 |   32 | 0.0520736   |         |            |                      |\n","| train_cifar_b22a4_00002 | PENDING  |                  |            4 |   32 |    8 | 0.00498188  |         |            |                      |\n","| train_cifar_b22a4_00003 | PENDING  |                  |           16 |    8 |  128 | 0.00841198  |         |            |                      |\n","| train_cifar_b22a4_00004 | PENDING  |                  |            2 |  128 |    8 | 0.0115033   |         |            |                      |\n","| train_cifar_b22a4_00005 | PENDING  |                  |           16 |  256 |   64 | 0.000892888 |         |            |                      |\n","| train_cifar_b22a4_00006 | PENDING  |                  |            4 |   32 |  256 | 0.0251675   |         |            |                      |\n","| train_cifar_b22a4_00007 | PENDING  |                  |           16 |  256 |   64 | 0.000238698 |         |            |                      |\n","| train_cifar_b22a4_00008 | PENDING  |                  |            2 |  128 |  256 | 0.0198986   |         |            |                      |\n","| train_cifar_b22a4_00009 | PENDING  |                  |           16 |  128 |   64 | 0.000264479 |         |            |                      |\n","+-------------------------+----------+------------------+--------------+------+------+-------------+---------+------------+----------------------+\n","\n","\n","== Status ==\n","Current time: 2023-03-17 01:41:39 (running for 00:01:10.85)\n","Memory usage on this node: 3.7/12.7 GiB \n","Using AsyncHyperBand: num_stopped=0\n","Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: -2.299063328170776\n","Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.39 GiB heap, 0.0/3.69 GiB objects\n","Result logdir: /root/ray_results/train_cifar_2023-03-17_01-40-28\n","Number of trials: 10/10 (9 PENDING, 1 RUNNING)\n","+-------------------------+----------+------------------+--------------+------+------+-------------+---------+------------+----------------------+\n","| Trial name              | status   | loc              |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n","|-------------------------+----------+------------------+--------------+------+------+-------------+---------+------------+----------------------|\n","| train_cifar_b22a4_00000 | RUNNING  | 172.28.0.12:4162 |           16 |   32 |   32 | 0.000414851 | 2.29906 |     0.1482 |                    1 |\n","| train_cifar_b22a4_00001 | PENDING  |                  |            8 |   16 |   32 | 0.0520736   |         |            |                      |\n","| train_cifar_b22a4_00002 | PENDING  |                  |            4 |   32 |    8 | 0.00498188  |         |            |                      |\n","| train_cifar_b22a4_00003 | PENDING  |                  |           16 |    8 |  128 | 0.00841198  |         |            |                      |\n","| train_cifar_b22a4_00004 | PENDING  |                  |            2 |  128 |    8 | 0.0115033   |         |            |                      |\n","| train_cifar_b22a4_00005 | PENDING  |                  |           16 |  256 |   64 | 0.000892888 |         |            |                      |\n","| train_cifar_b22a4_00006 | PENDING  |                  |            4 |   32 |  256 | 0.0251675   |         |            |                      |\n","| train_cifar_b22a4_00007 | PENDING  |                  |           16 |  256 |   64 | 0.000238698 |         |            |                      |\n","| train_cifar_b22a4_00008 | PENDING  |                  |            2 |  128 |  256 | 0.0198986   |         |            |                      |\n","| train_cifar_b22a4_00009 | PENDING  |                  |           16 |  128 |   64 | 0.000264479 |         |            |                      |\n","+-------------------------+----------+------------------+--------------+------+------+-------------+---------+------------+----------------------+\n","\n","\n","== Status ==\n","Current time: 2023-03-17 01:41:46 (running for 00:01:17.74)\n","Memory usage on this node: 3.7/12.7 GiB \n","Using AsyncHyperBand: num_stopped=0\n","Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: -2.099749384880066 | Iter 1.000: -2.299063328170776\n","Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.39 GiB heap, 0.0/3.69 GiB objects\n","Result logdir: /root/ray_results/train_cifar_2023-03-17_01-40-28\n","Number of trials: 10/10 (9 PENDING, 1 RUNNING)\n","+-------------------------+----------+------------------+--------------+------+------+-------------+---------+------------+----------------------+\n","| Trial name              | status   | loc              |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n","|-------------------------+----------+------------------+--------------+------+------+-------------+---------+------------+----------------------|\n","| train_cifar_b22a4_00000 | RUNNING  | 172.28.0.12:4162 |           16 |   32 |   32 | 0.000414851 | 2.09975 |     0.2316 |                    2 |\n","| train_cifar_b22a4_00001 | PENDING  |                  |            8 |   16 |   32 | 0.0520736   |         |            |                      |\n","| train_cifar_b22a4_00002 | PENDING  |                  |            4 |   32 |    8 | 0.00498188  |         |            |                      |\n","| train_cifar_b22a4_00003 | PENDING  |                  |           16 |    8 |  128 | 0.00841198  |         |            |                      |\n","| train_cifar_b22a4_00004 | PENDING  |                  |            2 |  128 |    8 | 0.0115033   |         |            |                      |\n","| train_cifar_b22a4_00005 | PENDING  |                  |           16 |  256 |   64 | 0.000892888 |         |            |                      |\n","| train_cifar_b22a4_00006 | PENDING  |                  |            4 |   32 |  256 | 0.0251675   |         |            |                      |\n","| train_cifar_b22a4_00007 | PENDING  |                  |           16 |  256 |   64 | 0.000238698 |         |            |                      |\n","| train_cifar_b22a4_00008 | PENDING  |                  |            2 |  128 |  256 | 0.0198986   |         |            |                      |\n","| train_cifar_b22a4_00009 | PENDING  |                  |           16 |  128 |   64 | 0.000264479 |         |            |                      |\n","+-------------------------+----------+------------------+--------------+------+------+-------------+---------+------------+----------------------+\n","\n","\n","== Status ==\n","Current time: 2023-03-17 01:41:51 (running for 00:01:22.78)\n","Memory usage on this node: 3.7/12.7 GiB \n","Using AsyncHyperBand: num_stopped=0\n","Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: -2.099749384880066 | Iter 1.000: -2.299063328170776\n","Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.39 GiB heap, 0.0/3.69 GiB objects\n","Result logdir: /root/ray_results/train_cifar_2023-03-17_01-40-28\n","Number of trials: 10/10 (9 PENDING, 1 RUNNING)\n","+-------------------------+----------+------------------+--------------+------+------+-------------+---------+------------+----------------------+\n","| Trial name              | status   | loc              |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n","|-------------------------+----------+------------------+--------------+------+------+-------------+---------+------------+----------------------|\n","| train_cifar_b22a4_00000 | RUNNING  | 172.28.0.12:4162 |           16 |   32 |   32 | 0.000414851 | 2.09975 |     0.2316 |                    2 |\n","| train_cifar_b22a4_00001 | PENDING  |                  |            8 |   16 |   32 | 0.0520736   |         |            |                      |\n","| train_cifar_b22a4_00002 | PENDING  |                  |            4 |   32 |    8 | 0.00498188  |         |            |                      |\n","| train_cifar_b22a4_00003 | PENDING  |                  |           16 |    8 |  128 | 0.00841198  |         |            |                      |\n","| train_cifar_b22a4_00004 | PENDING  |                  |            2 |  128 |    8 | 0.0115033   |         |            |                      |\n","| train_cifar_b22a4_00005 | PENDING  |                  |           16 |  256 |   64 | 0.000892888 |         |            |                      |\n","| train_cifar_b22a4_00006 | PENDING  |                  |            4 |   32 |  256 | 0.0251675   |         |            |                      |\n","| train_cifar_b22a4_00007 | PENDING  |                  |           16 |  256 |   64 | 0.000238698 |         |            |                      |\n","| train_cifar_b22a4_00008 | PENDING  |                  |            2 |  128 |  256 | 0.0198986   |         |            |                      |\n","| train_cifar_b22a4_00009 | PENDING  |                  |           16 |  128 |   64 | 0.000264479 |         |            |                      |\n","+-------------------------+----------+------------------+--------------+------+------+-------------+---------+------------+----------------------+\n","\n","\n","== Status ==\n","Current time: 2023-03-17 01:41:56 (running for 00:01:27.82)\n","Memory usage on this node: 3.7/12.7 GiB \n","Using AsyncHyperBand: num_stopped=0\n","Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: -2.099749384880066 | Iter 1.000: -2.299063328170776\n","Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.39 GiB heap, 0.0/3.69 GiB objects\n","Result logdir: /root/ray_results/train_cifar_2023-03-17_01-40-28\n","Number of trials: 10/10 (9 PENDING, 1 RUNNING)\n","+-------------------------+----------+------------------+--------------+------+------+-------------+---------+------------+----------------------+\n","| Trial name              | status   | loc              |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n","|-------------------------+----------+------------------+--------------+------+------+-------------+---------+------------+----------------------|\n","| train_cifar_b22a4_00000 | RUNNING  | 172.28.0.12:4162 |           16 |   32 |   32 | 0.000414851 | 2.09975 |     0.2316 |                    2 |\n","| train_cifar_b22a4_00001 | PENDING  |                  |            8 |   16 |   32 | 0.0520736   |         |            |                      |\n","| train_cifar_b22a4_00002 | PENDING  |                  |            4 |   32 |    8 | 0.00498188  |         |            |                      |\n","| train_cifar_b22a4_00003 | PENDING  |                  |           16 |    8 |  128 | 0.00841198  |         |            |                      |\n","| train_cifar_b22a4_00004 | PENDING  |                  |            2 |  128 |    8 | 0.0115033   |         |            |                      |\n","| train_cifar_b22a4_00005 | PENDING  |                  |           16 |  256 |   64 | 0.000892888 |         |            |                      |\n","| train_cifar_b22a4_00006 | PENDING  |                  |            4 |   32 |  256 | 0.0251675   |         |            |                      |\n","| train_cifar_b22a4_00007 | PENDING  |                  |           16 |  256 |   64 | 0.000238698 |         |            |                      |\n","| train_cifar_b22a4_00008 | PENDING  |                  |            2 |  128 |  256 | 0.0198986   |         |            |                      |\n","| train_cifar_b22a4_00009 | PENDING  |                  |           16 |  128 |   64 | 0.000264479 |         |            |                      |\n","+-------------------------+----------+------------------+--------------+------+------+-------------+---------+------------+----------------------+\n","\n","\n","== Status ==\n","Current time: 2023-03-17 01:42:01 (running for 00:01:32.84)\n","Memory usage on this node: 3.8/12.7 GiB \n","Using AsyncHyperBand: num_stopped=0\n","Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: -2.099749384880066 | Iter 1.000: -2.299063328170776\n","Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.39 GiB heap, 0.0/3.69 GiB objects\n","Result logdir: /root/ray_results/train_cifar_2023-03-17_01-40-28\n","Number of trials: 10/10 (9 PENDING, 1 RUNNING)\n","+-------------------------+----------+------------------+--------------+------+------+-------------+---------+------------+----------------------+\n","| Trial name              | status   | loc              |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n","|-------------------------+----------+------------------+--------------+------+------+-------------+---------+------------+----------------------|\n","| train_cifar_b22a4_00000 | RUNNING  | 172.28.0.12:4162 |           16 |   32 |   32 | 0.000414851 | 2.09975 |     0.2316 |                    2 |\n","| train_cifar_b22a4_00001 | PENDING  |                  |            8 |   16 |   32 | 0.0520736   |         |            |                      |\n","| train_cifar_b22a4_00002 | PENDING  |                  |            4 |   32 |    8 | 0.00498188  |         |            |                      |\n","| train_cifar_b22a4_00003 | PENDING  |                  |           16 |    8 |  128 | 0.00841198  |         |            |                      |\n","| train_cifar_b22a4_00004 | PENDING  |                  |            2 |  128 |    8 | 0.0115033   |         |            |                      |\n","| train_cifar_b22a4_00005 | PENDING  |                  |           16 |  256 |   64 | 0.000892888 |         |            |                      |\n","| train_cifar_b22a4_00006 | PENDING  |                  |            4 |   32 |  256 | 0.0251675   |         |            |                      |\n","| train_cifar_b22a4_00007 | PENDING  |                  |           16 |  256 |   64 | 0.000238698 |         |            |                      |\n","| train_cifar_b22a4_00008 | PENDING  |                  |            2 |  128 |  256 | 0.0198986   |         |            |                      |\n","| train_cifar_b22a4_00009 | PENDING  |                  |           16 |  128 |   64 | 0.000264479 |         |            |                      |\n","+-------------------------+----------+------------------+--------------+------+------+-------------+---------+------------+----------------------+\n","\n","\n","== Status ==\n","Current time: 2023-03-17 01:42:06 (running for 00:01:37.85)\n","Memory usage on this node: 3.8/12.7 GiB \n","Using AsyncHyperBand: num_stopped=0\n","Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: -2.099749384880066 | Iter 1.000: -2.299063328170776\n","Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.39 GiB heap, 0.0/3.69 GiB objects\n","Result logdir: /root/ray_results/train_cifar_2023-03-17_01-40-28\n","Number of trials: 10/10 (9 PENDING, 1 RUNNING)\n","+-------------------------+----------+------------------+--------------+------+------+-------------+---------+------------+----------------------+\n","| Trial name              | status   | loc              |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n","|-------------------------+----------+------------------+--------------+------+------+-------------+---------+------------+----------------------|\n","| train_cifar_b22a4_00000 | RUNNING  | 172.28.0.12:4162 |           16 |   32 |   32 | 0.000414851 | 2.09975 |     0.2316 |                    2 |\n","| train_cifar_b22a4_00001 | PENDING  |                  |            8 |   16 |   32 | 0.0520736   |         |            |                      |\n","| train_cifar_b22a4_00002 | PENDING  |                  |            4 |   32 |    8 | 0.00498188  |         |            |                      |\n","| train_cifar_b22a4_00003 | PENDING  |                  |           16 |    8 |  128 | 0.00841198  |         |            |                      |\n","| train_cifar_b22a4_00004 | PENDING  |                  |            2 |  128 |    8 | 0.0115033   |         |            |                      |\n","| train_cifar_b22a4_00005 | PENDING  |                  |           16 |  256 |   64 | 0.000892888 |         |            |                      |\n","| train_cifar_b22a4_00006 | PENDING  |                  |            4 |   32 |  256 | 0.0251675   |         |            |                      |\n","| train_cifar_b22a4_00007 | PENDING  |                  |           16 |  256 |   64 | 0.000238698 |         |            |                      |\n","| train_cifar_b22a4_00008 | PENDING  |                  |            2 |  128 |  256 | 0.0198986   |         |            |                      |\n","| train_cifar_b22a4_00009 | PENDING  |                  |           16 |  128 |   64 | 0.000264479 |         |            |                      |\n","+-------------------------+----------+------------------+--------------+------+------+-------------+---------+------------+----------------------+\n","\n","\n","== Status ==\n","Current time: 2023-03-17 01:42:11 (running for 00:01:42.87)\n","Memory usage on this node: 3.8/12.7 GiB \n","Using AsyncHyperBand: num_stopped=0\n","Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: -2.099749384880066 | Iter 1.000: -2.299063328170776\n","Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.39 GiB heap, 0.0/3.69 GiB objects\n","Result logdir: /root/ray_results/train_cifar_2023-03-17_01-40-28\n","Number of trials: 10/10 (9 PENDING, 1 RUNNING)\n","+-------------------------+----------+------------------+--------------+------+------+-------------+---------+------------+----------------------+\n","| Trial name              | status   | loc              |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n","|-------------------------+----------+------------------+--------------+------+------+-------------+---------+------------+----------------------|\n","| train_cifar_b22a4_00000 | RUNNING  | 172.28.0.12:4162 |           16 |   32 |   32 | 0.000414851 | 2.09975 |     0.2316 |                    2 |\n","| train_cifar_b22a4_00001 | PENDING  |                  |            8 |   16 |   32 | 0.0520736   |         |            |                      |\n","| train_cifar_b22a4_00002 | PENDING  |                  |            4 |   32 |    8 | 0.00498188  |         |            |                      |\n","| train_cifar_b22a4_00003 | PENDING  |                  |           16 |    8 |  128 | 0.00841198  |         |            |                      |\n","| train_cifar_b22a4_00004 | PENDING  |                  |            2 |  128 |    8 | 0.0115033   |         |            |                      |\n","| train_cifar_b22a4_00005 | PENDING  |                  |           16 |  256 |   64 | 0.000892888 |         |            |                      |\n","| train_cifar_b22a4_00006 | PENDING  |                  |            4 |   32 |  256 | 0.0251675   |         |            |                      |\n","| train_cifar_b22a4_00007 | PENDING  |                  |           16 |  256 |   64 | 0.000238698 |         |            |                      |\n","| train_cifar_b22a4_00008 | PENDING  |                  |            2 |  128 |  256 | 0.0198986   |         |            |                      |\n","| train_cifar_b22a4_00009 | PENDING  |                  |           16 |  128 |   64 | 0.000264479 |         |            |                      |\n","+-------------------------+----------+------------------+--------------+------+------+-------------+---------+------------+----------------------+\n","\n","\n","\u001b[2m\u001b[36m(func pid=4162)\u001b[0m [3,  2000] loss: 2.013\n","== Status ==\n","Current time: 2023-03-17 01:42:16 (running for 00:01:47.89)\n","Memory usage on this node: 3.8/12.7 GiB \n","Using AsyncHyperBand: num_stopped=0\n","Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: -2.099749384880066 | Iter 1.000: -2.299063328170776\n","Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.39 GiB heap, 0.0/3.69 GiB objects\n","Result logdir: /root/ray_results/train_cifar_2023-03-17_01-40-28\n","Number of trials: 10/10 (9 PENDING, 1 RUNNING)\n","+-------------------------+----------+------------------+--------------+------+------+-------------+---------+------------+----------------------+\n","| Trial name              | status   | loc              |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n","|-------------------------+----------+------------------+--------------+------+------+-------------+---------+------------+----------------------|\n","| train_cifar_b22a4_00000 | RUNNING  | 172.28.0.12:4162 |           16 |   32 |   32 | 0.000414851 | 2.09975 |     0.2316 |                    2 |\n","| train_cifar_b22a4_00001 | PENDING  |                  |            8 |   16 |   32 | 0.0520736   |         |            |                      |\n","| train_cifar_b22a4_00002 | PENDING  |                  |            4 |   32 |    8 | 0.00498188  |         |            |                      |\n","| train_cifar_b22a4_00003 | PENDING  |                  |           16 |    8 |  128 | 0.00841198  |         |            |                      |\n","| train_cifar_b22a4_00004 | PENDING  |                  |            2 |  128 |    8 | 0.0115033   |         |            |                      |\n","| train_cifar_b22a4_00005 | PENDING  |                  |           16 |  256 |   64 | 0.000892888 |         |            |                      |\n","| train_cifar_b22a4_00006 | PENDING  |                  |            4 |   32 |  256 | 0.0251675   |         |            |                      |\n","| train_cifar_b22a4_00007 | PENDING  |                  |           16 |  256 |   64 | 0.000238698 |         |            |                      |\n","| train_cifar_b22a4_00008 | PENDING  |                  |            2 |  128 |  256 | 0.0198986   |         |            |                      |\n","| train_cifar_b22a4_00009 | PENDING  |                  |           16 |  128 |   64 | 0.000264479 |         |            |                      |\n","+-------------------------+----------+------------------+--------------+------+------+-------------+---------+------------+----------------------+\n","\n","\n","== Status ==\n","Current time: 2023-03-17 01:42:21 (running for 00:01:52.89)\n","Memory usage on this node: 3.8/12.7 GiB \n","Using AsyncHyperBand: num_stopped=0\n","Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: -2.099749384880066 | Iter 1.000: -2.299063328170776\n","Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.39 GiB heap, 0.0/3.69 GiB objects\n","Result logdir: /root/ray_results/train_cifar_2023-03-17_01-40-28\n","Number of trials: 10/10 (9 PENDING, 1 RUNNING)\n","+-------------------------+----------+------------------+--------------+------+------+-------------+---------+------------+----------------------+\n","| Trial name              | status   | loc              |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n","|-------------------------+----------+------------------+--------------+------+------+-------------+---------+------------+----------------------|\n","| train_cifar_b22a4_00000 | RUNNING  | 172.28.0.12:4162 |           16 |   32 |   32 | 0.000414851 | 2.09975 |     0.2316 |                    2 |\n","| train_cifar_b22a4_00001 | PENDING  |                  |            8 |   16 |   32 | 0.0520736   |         |            |                      |\n","| train_cifar_b22a4_00002 | PENDING  |                  |            4 |   32 |    8 | 0.00498188  |         |            |                      |\n","| train_cifar_b22a4_00003 | PENDING  |                  |           16 |    8 |  128 | 0.00841198  |         |            |                      |\n","| train_cifar_b22a4_00004 | PENDING  |                  |            2 |  128 |    8 | 0.0115033   |         |            |                      |\n","| train_cifar_b22a4_00005 | PENDING  |                  |           16 |  256 |   64 | 0.000892888 |         |            |                      |\n","| train_cifar_b22a4_00006 | PENDING  |                  |            4 |   32 |  256 | 0.0251675   |         |            |                      |\n","| train_cifar_b22a4_00007 | PENDING  |                  |           16 |  256 |   64 | 0.000238698 |         |            |                      |\n","| train_cifar_b22a4_00008 | PENDING  |                  |            2 |  128 |  256 | 0.0198986   |         |            |                      |\n","| train_cifar_b22a4_00009 | PENDING  |                  |           16 |  128 |   64 | 0.000264479 |         |            |                      |\n","+-------------------------+----------+------------------+--------------+------+------+-------------+---------+------------+----------------------+\n","\n","\n","== Status ==\n","Current time: 2023-03-17 01:42:29 (running for 00:02:01.29)\n","Memory usage on this node: 3.9/12.7 GiB \n","Using AsyncHyperBand: num_stopped=0\n","Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: -2.099749384880066 | Iter 1.000: -2.299063328170776\n","Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.39 GiB heap, 0.0/3.69 GiB objects\n","Result logdir: /root/ray_results/train_cifar_2023-03-17_01-40-28\n","Number of trials: 10/10 (9 PENDING, 1 RUNNING)\n","+-------------------------+----------+------------------+--------------+------+------+-------------+---------+------------+----------------------+\n","| Trial name              | status   | loc              |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n","|-------------------------+----------+------------------+--------------+------+------+-------------+---------+------------+----------------------|\n","| train_cifar_b22a4_00000 | RUNNING  | 172.28.0.12:4162 |           16 |   32 |   32 | 0.000414851 | 1.90167 |     0.2986 |                    3 |\n","| train_cifar_b22a4_00001 | PENDING  |                  |            8 |   16 |   32 | 0.0520736   |         |            |                      |\n","| train_cifar_b22a4_00002 | PENDING  |                  |            4 |   32 |    8 | 0.00498188  |         |            |                      |\n","| train_cifar_b22a4_00003 | PENDING  |                  |           16 |    8 |  128 | 0.00841198  |         |            |                      |\n","| train_cifar_b22a4_00004 | PENDING  |                  |            2 |  128 |    8 | 0.0115033   |         |            |                      |\n","| train_cifar_b22a4_00005 | PENDING  |                  |           16 |  256 |   64 | 0.000892888 |         |            |                      |\n","| train_cifar_b22a4_00006 | PENDING  |                  |            4 |   32 |  256 | 0.0251675   |         |            |                      |\n","| train_cifar_b22a4_00007 | PENDING  |                  |           16 |  256 |   64 | 0.000238698 |         |            |                      |\n","| train_cifar_b22a4_00008 | PENDING  |                  |            2 |  128 |  256 | 0.0198986   |         |            |                      |\n","| train_cifar_b22a4_00009 | PENDING  |                  |           16 |  128 |   64 | 0.000264479 |         |            |                      |\n","+-------------------------+----------+------------------+--------------+------+------+-------------+---------+------------+----------------------+\n","\n","\n","== Status ==\n","Current time: 2023-03-17 01:42:34 (running for 00:02:06.30)\n","Memory usage on this node: 3.9/12.7 GiB \n","Using AsyncHyperBand: num_stopped=0\n","Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: -2.099749384880066 | Iter 1.000: -2.299063328170776\n","Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.39 GiB heap, 0.0/3.69 GiB objects\n","Result logdir: /root/ray_results/train_cifar_2023-03-17_01-40-28\n","Number of trials: 10/10 (9 PENDING, 1 RUNNING)\n","+-------------------------+----------+------------------+--------------+------+------+-------------+---------+------------+----------------------+\n","| Trial name              | status   | loc              |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n","|-------------------------+----------+------------------+--------------+------+------+-------------+---------+------------+----------------------|\n","| train_cifar_b22a4_00000 | RUNNING  | 172.28.0.12:4162 |           16 |   32 |   32 | 0.000414851 | 1.90167 |     0.2986 |                    3 |\n","| train_cifar_b22a4_00001 | PENDING  |                  |            8 |   16 |   32 | 0.0520736   |         |            |                      |\n","| train_cifar_b22a4_00002 | PENDING  |                  |            4 |   32 |    8 | 0.00498188  |         |            |                      |\n","| train_cifar_b22a4_00003 | PENDING  |                  |           16 |    8 |  128 | 0.00841198  |         |            |                      |\n","| train_cifar_b22a4_00004 | PENDING  |                  |            2 |  128 |    8 | 0.0115033   |         |            |                      |\n","| train_cifar_b22a4_00005 | PENDING  |                  |           16 |  256 |   64 | 0.000892888 |         |            |                      |\n","| train_cifar_b22a4_00006 | PENDING  |                  |            4 |   32 |  256 | 0.0251675   |         |            |                      |\n","| train_cifar_b22a4_00007 | PENDING  |                  |           16 |  256 |   64 | 0.000238698 |         |            |                      |\n","| train_cifar_b22a4_00008 | PENDING  |                  |            2 |  128 |  256 | 0.0198986   |         |            |                      |\n","| train_cifar_b22a4_00009 | PENDING  |                  |           16 |  128 |   64 | 0.000264479 |         |            |                      |\n","+-------------------------+----------+------------------+--------------+------+------+-------------+---------+------------+----------------------+\n","\n","\n","== Status ==\n","Current time: 2023-03-17 01:42:39 (running for 00:02:11.32)\n","Memory usage on this node: 3.9/12.7 GiB \n","Using AsyncHyperBand: num_stopped=0\n","Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: -2.099749384880066 | Iter 1.000: -2.299063328170776\n","Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.39 GiB heap, 0.0/3.69 GiB objects\n","Result logdir: /root/ray_results/train_cifar_2023-03-17_01-40-28\n","Number of trials: 10/10 (9 PENDING, 1 RUNNING)\n","+-------------------------+----------+------------------+--------------+------+------+-------------+---------+------------+----------------------+\n","| Trial name              | status   | loc              |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n","|-------------------------+----------+------------------+--------------+------+------+-------------+---------+------------+----------------------|\n","| train_cifar_b22a4_00000 | RUNNING  | 172.28.0.12:4162 |           16 |   32 |   32 | 0.000414851 | 1.90167 |     0.2986 |                    3 |\n","| train_cifar_b22a4_00001 | PENDING  |                  |            8 |   16 |   32 | 0.0520736   |         |            |                      |\n","| train_cifar_b22a4_00002 | PENDING  |                  |            4 |   32 |    8 | 0.00498188  |         |            |                      |\n","| train_cifar_b22a4_00003 | PENDING  |                  |           16 |    8 |  128 | 0.00841198  |         |            |                      |\n","| train_cifar_b22a4_00004 | PENDING  |                  |            2 |  128 |    8 | 0.0115033   |         |            |                      |\n","| train_cifar_b22a4_00005 | PENDING  |                  |           16 |  256 |   64 | 0.000892888 |         |            |                      |\n","| train_cifar_b22a4_00006 | PENDING  |                  |            4 |   32 |  256 | 0.0251675   |         |            |                      |\n","| train_cifar_b22a4_00007 | PENDING  |                  |           16 |  256 |   64 | 0.000238698 |         |            |                      |\n","| train_cifar_b22a4_00008 | PENDING  |                  |            2 |  128 |  256 | 0.0198986   |         |            |                      |\n","| train_cifar_b22a4_00009 | PENDING  |                  |           16 |  128 |   64 | 0.000264479 |         |            |                      |\n","+-------------------------+----------+------------------+--------------+------+------+-------------+---------+------------+----------------------+\n","\n","\n","== Status ==\n","Current time: 2023-03-17 01:42:44 (running for 00:02:16.34)\n","Memory usage on this node: 3.9/12.7 GiB \n","Using AsyncHyperBand: num_stopped=0\n","Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: -2.099749384880066 | Iter 1.000: -2.299063328170776\n","Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.39 GiB heap, 0.0/3.69 GiB objects\n","Result logdir: /root/ray_results/train_cifar_2023-03-17_01-40-28\n","Number of trials: 10/10 (9 PENDING, 1 RUNNING)\n","+-------------------------+----------+------------------+--------------+------+------+-------------+---------+------------+----------------------+\n","| Trial name              | status   | loc              |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n","|-------------------------+----------+------------------+--------------+------+------+-------------+---------+------------+----------------------|\n","| train_cifar_b22a4_00000 | RUNNING  | 172.28.0.12:4162 |           16 |   32 |   32 | 0.000414851 | 1.90167 |     0.2986 |                    3 |\n","| train_cifar_b22a4_00001 | PENDING  |                  |            8 |   16 |   32 | 0.0520736   |         |            |                      |\n","| train_cifar_b22a4_00002 | PENDING  |                  |            4 |   32 |    8 | 0.00498188  |         |            |                      |\n","| train_cifar_b22a4_00003 | PENDING  |                  |           16 |    8 |  128 | 0.00841198  |         |            |                      |\n","| train_cifar_b22a4_00004 | PENDING  |                  |            2 |  128 |    8 | 0.0115033   |         |            |                      |\n","| train_cifar_b22a4_00005 | PENDING  |                  |           16 |  256 |   64 | 0.000892888 |         |            |                      |\n","| train_cifar_b22a4_00006 | PENDING  |                  |            4 |   32 |  256 | 0.0251675   |         |            |                      |\n","| train_cifar_b22a4_00007 | PENDING  |                  |           16 |  256 |   64 | 0.000238698 |         |            |                      |\n","| train_cifar_b22a4_00008 | PENDING  |                  |            2 |  128 |  256 | 0.0198986   |         |            |                      |\n","| train_cifar_b22a4_00009 | PENDING  |                  |           16 |  128 |   64 | 0.000264479 |         |            |                      |\n","+-------------------------+----------+------------------+--------------+------+------+-------------+---------+------------+----------------------+\n","\n","\n","\u001b[2m\u001b[36m(func pid=4162)\u001b[0m [4,  2000] loss: 1.796\n","== Status ==\n","Current time: 2023-03-17 01:42:49 (running for 00:02:21.36)\n","Memory usage on this node: 3.9/12.7 GiB \n","Using AsyncHyperBand: num_stopped=0\n","Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: -2.099749384880066 | Iter 1.000: -2.299063328170776\n","Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.39 GiB heap, 0.0/3.69 GiB objects\n","Result logdir: /root/ray_results/train_cifar_2023-03-17_01-40-28\n","Number of trials: 10/10 (9 PENDING, 1 RUNNING)\n","+-------------------------+----------+------------------+--------------+------+------+-------------+---------+------------+----------------------+\n","| Trial name              | status   | loc              |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n","|-------------------------+----------+------------------+--------------+------+------+-------------+---------+------------+----------------------|\n","| train_cifar_b22a4_00000 | RUNNING  | 172.28.0.12:4162 |           16 |   32 |   32 | 0.000414851 | 1.90167 |     0.2986 |                    3 |\n","| train_cifar_b22a4_00001 | PENDING  |                  |            8 |   16 |   32 | 0.0520736   |         |            |                      |\n","| train_cifar_b22a4_00002 | PENDING  |                  |            4 |   32 |    8 | 0.00498188  |         |            |                      |\n","| train_cifar_b22a4_00003 | PENDING  |                  |           16 |    8 |  128 | 0.00841198  |         |            |                      |\n","| train_cifar_b22a4_00004 | PENDING  |                  |            2 |  128 |    8 | 0.0115033   |         |            |                      |\n","| train_cifar_b22a4_00005 | PENDING  |                  |           16 |  256 |   64 | 0.000892888 |         |            |                      |\n","| train_cifar_b22a4_00006 | PENDING  |                  |            4 |   32 |  256 | 0.0251675   |         |            |                      |\n","| train_cifar_b22a4_00007 | PENDING  |                  |           16 |  256 |   64 | 0.000238698 |         |            |                      |\n","| train_cifar_b22a4_00008 | PENDING  |                  |            2 |  128 |  256 | 0.0198986   |         |            |                      |\n","| train_cifar_b22a4_00009 | PENDING  |                  |           16 |  128 |   64 | 0.000264479 |         |            |                      |\n","+-------------------------+----------+------------------+--------------+------+------+-------------+---------+------------+----------------------+\n","\n","\n","== Status ==\n","Current time: 2023-03-17 01:42:54 (running for 00:02:26.37)\n","Memory usage on this node: 3.9/12.7 GiB \n","Using AsyncHyperBand: num_stopped=0\n","Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: -2.099749384880066 | Iter 1.000: -2.299063328170776\n","Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.39 GiB heap, 0.0/3.69 GiB objects\n","Result logdir: /root/ray_results/train_cifar_2023-03-17_01-40-28\n","Number of trials: 10/10 (9 PENDING, 1 RUNNING)\n","+-------------------------+----------+------------------+--------------+------+------+-------------+---------+------------+----------------------+\n","| Trial name              | status   | loc              |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n","|-------------------------+----------+------------------+--------------+------+------+-------------+---------+------------+----------------------|\n","| train_cifar_b22a4_00000 | RUNNING  | 172.28.0.12:4162 |           16 |   32 |   32 | 0.000414851 | 1.90167 |     0.2986 |                    3 |\n","| train_cifar_b22a4_00001 | PENDING  |                  |            8 |   16 |   32 | 0.0520736   |         |            |                      |\n","| train_cifar_b22a4_00002 | PENDING  |                  |            4 |   32 |    8 | 0.00498188  |         |            |                      |\n","| train_cifar_b22a4_00003 | PENDING  |                  |           16 |    8 |  128 | 0.00841198  |         |            |                      |\n","| train_cifar_b22a4_00004 | PENDING  |                  |            2 |  128 |    8 | 0.0115033   |         |            |                      |\n","| train_cifar_b22a4_00005 | PENDING  |                  |           16 |  256 |   64 | 0.000892888 |         |            |                      |\n","| train_cifar_b22a4_00006 | PENDING  |                  |            4 |   32 |  256 | 0.0251675   |         |            |                      |\n","| train_cifar_b22a4_00007 | PENDING  |                  |           16 |  256 |   64 | 0.000238698 |         |            |                      |\n","| train_cifar_b22a4_00008 | PENDING  |                  |            2 |  128 |  256 | 0.0198986   |         |            |                      |\n","| train_cifar_b22a4_00009 | PENDING  |                  |           16 |  128 |   64 | 0.000264479 |         |            |                      |\n","+-------------------------+----------+------------------+--------------+------+------+-------------+---------+------------+----------------------+\n","\n","\n","== Status ==\n","Current time: 2023-03-17 01:43:01 (running for 00:02:32.89)\n","Memory usage on this node: 3.9/12.7 GiB \n","Using AsyncHyperBand: num_stopped=0\n","Bracket: Iter 8.000: None | Iter 4.000: -1.6692905458450318 | Iter 2.000: -2.099749384880066 | Iter 1.000: -2.299063328170776\n","Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.39 GiB heap, 0.0/3.69 GiB objects\n","Result logdir: /root/ray_results/train_cifar_2023-03-17_01-40-28\n","Number of trials: 10/10 (9 PENDING, 1 RUNNING)\n","+-------------------------+----------+------------------+--------------+------+------+-------------+---------+------------+----------------------+\n","| Trial name              | status   | loc              |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n","|-------------------------+----------+------------------+--------------+------+------+-------------+---------+------------+----------------------|\n","| train_cifar_b22a4_00000 | RUNNING  | 172.28.0.12:4162 |           16 |   32 |   32 | 0.000414851 | 1.66929 |      0.382 |                    4 |\n","| train_cifar_b22a4_00001 | PENDING  |                  |            8 |   16 |   32 | 0.0520736   |         |            |                      |\n","| train_cifar_b22a4_00002 | PENDING  |                  |            4 |   32 |    8 | 0.00498188  |         |            |                      |\n","| train_cifar_b22a4_00003 | PENDING  |                  |           16 |    8 |  128 | 0.00841198  |         |            |                      |\n","| train_cifar_b22a4_00004 | PENDING  |                  |            2 |  128 |    8 | 0.0115033   |         |            |                      |\n","| train_cifar_b22a4_00005 | PENDING  |                  |           16 |  256 |   64 | 0.000892888 |         |            |                      |\n","| train_cifar_b22a4_00006 | PENDING  |                  |            4 |   32 |  256 | 0.0251675   |         |            |                      |\n","| train_cifar_b22a4_00007 | PENDING  |                  |           16 |  256 |   64 | 0.000238698 |         |            |                      |\n","| train_cifar_b22a4_00008 | PENDING  |                  |            2 |  128 |  256 | 0.0198986   |         |            |                      |\n","| train_cifar_b22a4_00009 | PENDING  |                  |           16 |  128 |   64 | 0.000264479 |         |            |                      |\n","+-------------------------+----------+------------------+--------------+------+------+-------------+---------+------------+----------------------+\n","\n","\n","== Status ==\n","Current time: 2023-03-17 01:43:06 (running for 00:02:37.90)\n","Memory usage on this node: 3.9/12.7 GiB \n","Using AsyncHyperBand: num_stopped=0\n","Bracket: Iter 8.000: None | Iter 4.000: -1.6692905458450318 | Iter 2.000: -2.099749384880066 | Iter 1.000: -2.299063328170776\n","Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.39 GiB heap, 0.0/3.69 GiB objects\n","Result logdir: /root/ray_results/train_cifar_2023-03-17_01-40-28\n","Number of trials: 10/10 (9 PENDING, 1 RUNNING)\n","+-------------------------+----------+------------------+--------------+------+------+-------------+---------+------------+----------------------+\n","| Trial name              | status   | loc              |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n","|-------------------------+----------+------------------+--------------+------+------+-------------+---------+------------+----------------------|\n","| train_cifar_b22a4_00000 | RUNNING  | 172.28.0.12:4162 |           16 |   32 |   32 | 0.000414851 | 1.66929 |      0.382 |                    4 |\n","| train_cifar_b22a4_00001 | PENDING  |                  |            8 |   16 |   32 | 0.0520736   |         |            |                      |\n","| train_cifar_b22a4_00002 | PENDING  |                  |            4 |   32 |    8 | 0.00498188  |         |            |                      |\n","| train_cifar_b22a4_00003 | PENDING  |                  |           16 |    8 |  128 | 0.00841198  |         |            |                      |\n","| train_cifar_b22a4_00004 | PENDING  |                  |            2 |  128 |    8 | 0.0115033   |         |            |                      |\n","| train_cifar_b22a4_00005 | PENDING  |                  |           16 |  256 |   64 | 0.000892888 |         |            |                      |\n","| train_cifar_b22a4_00006 | PENDING  |                  |            4 |   32 |  256 | 0.0251675   |         |            |                      |\n","| train_cifar_b22a4_00007 | PENDING  |                  |           16 |  256 |   64 | 0.000238698 |         |            |                      |\n","| train_cifar_b22a4_00008 | PENDING  |                  |            2 |  128 |  256 | 0.0198986   |         |            |                      |\n","| train_cifar_b22a4_00009 | PENDING  |                  |           16 |  128 |   64 | 0.000264479 |         |            |                      |\n","+-------------------------+----------+------------------+--------------+------+------+-------------+---------+------------+----------------------+\n","\n","\n","== Status ==\n","Current time: 2023-03-17 01:43:11 (running for 00:02:42.91)\n","Memory usage on this node: 3.9/12.7 GiB \n","Using AsyncHyperBand: num_stopped=0\n","Bracket: Iter 8.000: None | Iter 4.000: -1.6692905458450318 | Iter 2.000: -2.099749384880066 | Iter 1.000: -2.299063328170776\n","Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.39 GiB heap, 0.0/3.69 GiB objects\n","Result logdir: /root/ray_results/train_cifar_2023-03-17_01-40-28\n","Number of trials: 10/10 (9 PENDING, 1 RUNNING)\n","+-------------------------+----------+------------------+--------------+------+------+-------------+---------+------------+----------------------+\n","| Trial name              | status   | loc              |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n","|-------------------------+----------+------------------+--------------+------+------+-------------+---------+------------+----------------------|\n","| train_cifar_b22a4_00000 | RUNNING  | 172.28.0.12:4162 |           16 |   32 |   32 | 0.000414851 | 1.66929 |      0.382 |                    4 |\n","| train_cifar_b22a4_00001 | PENDING  |                  |            8 |   16 |   32 | 0.0520736   |         |            |                      |\n","| train_cifar_b22a4_00002 | PENDING  |                  |            4 |   32 |    8 | 0.00498188  |         |            |                      |\n","| train_cifar_b22a4_00003 | PENDING  |                  |           16 |    8 |  128 | 0.00841198  |         |            |                      |\n","| train_cifar_b22a4_00004 | PENDING  |                  |            2 |  128 |    8 | 0.0115033   |         |            |                      |\n","| train_cifar_b22a4_00005 | PENDING  |                  |           16 |  256 |   64 | 0.000892888 |         |            |                      |\n","| train_cifar_b22a4_00006 | PENDING  |                  |            4 |   32 |  256 | 0.0251675   |         |            |                      |\n","| train_cifar_b22a4_00007 | PENDING  |                  |           16 |  256 |   64 | 0.000238698 |         |            |                      |\n","| train_cifar_b22a4_00008 | PENDING  |                  |            2 |  128 |  256 | 0.0198986   |         |            |                      |\n","| train_cifar_b22a4_00009 | PENDING  |                  |           16 |  128 |   64 | 0.000264479 |         |            |                      |\n","+-------------------------+----------+------------------+--------------+------+------+-------------+---------+------------+----------------------+\n","\n","\n","== Status ==\n","Current time: 2023-03-17 01:43:16 (running for 00:02:47.92)\n","Memory usage on this node: 3.9/12.7 GiB \n","Using AsyncHyperBand: num_stopped=0\n","Bracket: Iter 8.000: None | Iter 4.000: -1.6692905458450318 | Iter 2.000: -2.099749384880066 | Iter 1.000: -2.299063328170776\n","Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.39 GiB heap, 0.0/3.69 GiB objects\n","Result logdir: /root/ray_results/train_cifar_2023-03-17_01-40-28\n","Number of trials: 10/10 (9 PENDING, 1 RUNNING)\n","+-------------------------+----------+------------------+--------------+------+------+-------------+---------+------------+----------------------+\n","| Trial name              | status   | loc              |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n","|-------------------------+----------+------------------+--------------+------+------+-------------+---------+------------+----------------------|\n","| train_cifar_b22a4_00000 | RUNNING  | 172.28.0.12:4162 |           16 |   32 |   32 | 0.000414851 | 1.66929 |      0.382 |                    4 |\n","| train_cifar_b22a4_00001 | PENDING  |                  |            8 |   16 |   32 | 0.0520736   |         |            |                      |\n","| train_cifar_b22a4_00002 | PENDING  |                  |            4 |   32 |    8 | 0.00498188  |         |            |                      |\n","| train_cifar_b22a4_00003 | PENDING  |                  |           16 |    8 |  128 | 0.00841198  |         |            |                      |\n","| train_cifar_b22a4_00004 | PENDING  |                  |            2 |  128 |    8 | 0.0115033   |         |            |                      |\n","| train_cifar_b22a4_00005 | PENDING  |                  |           16 |  256 |   64 | 0.000892888 |         |            |                      |\n","| train_cifar_b22a4_00006 | PENDING  |                  |            4 |   32 |  256 | 0.0251675   |         |            |                      |\n","| train_cifar_b22a4_00007 | PENDING  |                  |           16 |  256 |   64 | 0.000238698 |         |            |                      |\n","| train_cifar_b22a4_00008 | PENDING  |                  |            2 |  128 |  256 | 0.0198986   |         |            |                      |\n","| train_cifar_b22a4_00009 | PENDING  |                  |           16 |  128 |   64 | 0.000264479 |         |            |                      |\n","+-------------------------+----------+------------------+--------------+------+------+-------------+---------+------------+----------------------+\n","\n","\n","\u001b[2m\u001b[36m(func pid=4162)\u001b[0m [5,  2000] loss: 1.627\n","== Status ==\n","Current time: 2023-03-17 01:43:21 (running for 00:02:52.94)\n","Memory usage on this node: 3.9/12.7 GiB \n","Using AsyncHyperBand: num_stopped=0\n","Bracket: Iter 8.000: None | Iter 4.000: -1.6692905458450318 | Iter 2.000: -2.099749384880066 | Iter 1.000: -2.299063328170776\n","Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.39 GiB heap, 0.0/3.69 GiB objects\n","Result logdir: /root/ray_results/train_cifar_2023-03-17_01-40-28\n","Number of trials: 10/10 (9 PENDING, 1 RUNNING)\n","+-------------------------+----------+------------------+--------------+------+------+-------------+---------+------------+----------------------+\n","| Trial name              | status   | loc              |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n","|-------------------------+----------+------------------+--------------+------+------+-------------+---------+------------+----------------------|\n","| train_cifar_b22a4_00000 | RUNNING  | 172.28.0.12:4162 |           16 |   32 |   32 | 0.000414851 | 1.66929 |      0.382 |                    4 |\n","| train_cifar_b22a4_00001 | PENDING  |                  |            8 |   16 |   32 | 0.0520736   |         |            |                      |\n","| train_cifar_b22a4_00002 | PENDING  |                  |            4 |   32 |    8 | 0.00498188  |         |            |                      |\n","| train_cifar_b22a4_00003 | PENDING  |                  |           16 |    8 |  128 | 0.00841198  |         |            |                      |\n","| train_cifar_b22a4_00004 | PENDING  |                  |            2 |  128 |    8 | 0.0115033   |         |            |                      |\n","| train_cifar_b22a4_00005 | PENDING  |                  |           16 |  256 |   64 | 0.000892888 |         |            |                      |\n","| train_cifar_b22a4_00006 | PENDING  |                  |            4 |   32 |  256 | 0.0251675   |         |            |                      |\n","| train_cifar_b22a4_00007 | PENDING  |                  |           16 |  256 |   64 | 0.000238698 |         |            |                      |\n","| train_cifar_b22a4_00008 | PENDING  |                  |            2 |  128 |  256 | 0.0198986   |         |            |                      |\n","| train_cifar_b22a4_00009 | PENDING  |                  |           16 |  128 |   64 | 0.000264479 |         |            |                      |\n","+-------------------------+----------+------------------+--------------+------+------+-------------+---------+------------+----------------------+\n","\n","\n","== Status ==\n","Current time: 2023-03-17 01:43:26 (running for 00:02:57.96)\n","Memory usage on this node: 3.9/12.7 GiB \n","Using AsyncHyperBand: num_stopped=0\n","Bracket: Iter 8.000: None | Iter 4.000: -1.6692905458450318 | Iter 2.000: -2.099749384880066 | Iter 1.000: -2.299063328170776\n","Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.39 GiB heap, 0.0/3.69 GiB objects\n","Result logdir: /root/ray_results/train_cifar_2023-03-17_01-40-28\n","Number of trials: 10/10 (9 PENDING, 1 RUNNING)\n","+-------------------------+----------+------------------+--------------+------+------+-------------+---------+------------+----------------------+\n","| Trial name              | status   | loc              |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n","|-------------------------+----------+------------------+--------------+------+------+-------------+---------+------------+----------------------|\n","| train_cifar_b22a4_00000 | RUNNING  | 172.28.0.12:4162 |           16 |   32 |   32 | 0.000414851 | 1.66929 |      0.382 |                    4 |\n","| train_cifar_b22a4_00001 | PENDING  |                  |            8 |   16 |   32 | 0.0520736   |         |            |                      |\n","| train_cifar_b22a4_00002 | PENDING  |                  |            4 |   32 |    8 | 0.00498188  |         |            |                      |\n","| train_cifar_b22a4_00003 | PENDING  |                  |           16 |    8 |  128 | 0.00841198  |         |            |                      |\n","| train_cifar_b22a4_00004 | PENDING  |                  |            2 |  128 |    8 | 0.0115033   |         |            |                      |\n","| train_cifar_b22a4_00005 | PENDING  |                  |           16 |  256 |   64 | 0.000892888 |         |            |                      |\n","| train_cifar_b22a4_00006 | PENDING  |                  |            4 |   32 |  256 | 0.0251675   |         |            |                      |\n","| train_cifar_b22a4_00007 | PENDING  |                  |           16 |  256 |   64 | 0.000238698 |         |            |                      |\n","| train_cifar_b22a4_00008 | PENDING  |                  |            2 |  128 |  256 | 0.0198986   |         |            |                      |\n","| train_cifar_b22a4_00009 | PENDING  |                  |           16 |  128 |   64 | 0.000264479 |         |            |                      |\n","+-------------------------+----------+------------------+--------------+------+------+-------------+---------+------------+----------------------+\n","\n","\n","== Status ==\n","Current time: 2023-03-17 01:43:32 (running for 00:03:04.62)\n","Memory usage on this node: 3.7/12.7 GiB \n","Using AsyncHyperBand: num_stopped=0\n","Bracket: Iter 8.000: None | Iter 4.000: -1.6692905458450318 | Iter 2.000: -2.099749384880066 | Iter 1.000: -2.299063328170776\n","Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.39 GiB heap, 0.0/3.69 GiB objects\n","Result logdir: /root/ray_results/train_cifar_2023-03-17_01-40-28\n","Number of trials: 10/10 (9 PENDING, 1 RUNNING)\n","+-------------------------+----------+------------------+--------------+------+------+-------------+---------+------------+----------------------+\n","| Trial name              | status   | loc              |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n","|-------------------------+----------+------------------+--------------+------+------+-------------+---------+------------+----------------------|\n","| train_cifar_b22a4_00000 | RUNNING  | 172.28.0.12:4162 |           16 |   32 |   32 | 0.000414851 | 1.58192 |     0.4174 |                    5 |\n","| train_cifar_b22a4_00001 | PENDING  |                  |            8 |   16 |   32 | 0.0520736   |         |            |                      |\n","| train_cifar_b22a4_00002 | PENDING  |                  |            4 |   32 |    8 | 0.00498188  |         |            |                      |\n","| train_cifar_b22a4_00003 | PENDING  |                  |           16 |    8 |  128 | 0.00841198  |         |            |                      |\n","| train_cifar_b22a4_00004 | PENDING  |                  |            2 |  128 |    8 | 0.0115033   |         |            |                      |\n","| train_cifar_b22a4_00005 | PENDING  |                  |           16 |  256 |   64 | 0.000892888 |         |            |                      |\n","| train_cifar_b22a4_00006 | PENDING  |                  |            4 |   32 |  256 | 0.0251675   |         |            |                      |\n","| train_cifar_b22a4_00007 | PENDING  |                  |           16 |  256 |   64 | 0.000238698 |         |            |                      |\n","| train_cifar_b22a4_00008 | PENDING  |                  |            2 |  128 |  256 | 0.0198986   |         |            |                      |\n","| train_cifar_b22a4_00009 | PENDING  |                  |           16 |  128 |   64 | 0.000264479 |         |            |                      |\n","+-------------------------+----------+------------------+--------------+------+------+-------------+---------+------------+----------------------+\n","\n","\n","== Status ==\n","Current time: 2023-03-17 01:43:37 (running for 00:03:09.63)\n","Memory usage on this node: 3.7/12.7 GiB \n","Using AsyncHyperBand: num_stopped=0\n","Bracket: Iter 8.000: None | Iter 4.000: -1.6692905458450318 | Iter 2.000: -2.099749384880066 | Iter 1.000: -2.299063328170776\n","Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.39 GiB heap, 0.0/3.69 GiB objects\n","Result logdir: /root/ray_results/train_cifar_2023-03-17_01-40-28\n","Number of trials: 10/10 (9 PENDING, 1 RUNNING)\n","+-------------------------+----------+------------------+--------------+------+------+-------------+---------+------------+----------------------+\n","| Trial name              | status   | loc              |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n","|-------------------------+----------+------------------+--------------+------+------+-------------+---------+------------+----------------------|\n","| train_cifar_b22a4_00000 | RUNNING  | 172.28.0.12:4162 |           16 |   32 |   32 | 0.000414851 | 1.58192 |     0.4174 |                    5 |\n","| train_cifar_b22a4_00001 | PENDING  |                  |            8 |   16 |   32 | 0.0520736   |         |            |                      |\n","| train_cifar_b22a4_00002 | PENDING  |                  |            4 |   32 |    8 | 0.00498188  |         |            |                      |\n","| train_cifar_b22a4_00003 | PENDING  |                  |           16 |    8 |  128 | 0.00841198  |         |            |                      |\n","| train_cifar_b22a4_00004 | PENDING  |                  |            2 |  128 |    8 | 0.0115033   |         |            |                      |\n","| train_cifar_b22a4_00005 | PENDING  |                  |           16 |  256 |   64 | 0.000892888 |         |            |                      |\n","| train_cifar_b22a4_00006 | PENDING  |                  |            4 |   32 |  256 | 0.0251675   |         |            |                      |\n","| train_cifar_b22a4_00007 | PENDING  |                  |           16 |  256 |   64 | 0.000238698 |         |            |                      |\n","| train_cifar_b22a4_00008 | PENDING  |                  |            2 |  128 |  256 | 0.0198986   |         |            |                      |\n","| train_cifar_b22a4_00009 | PENDING  |                  |           16 |  128 |   64 | 0.000264479 |         |            |                      |\n","+-------------------------+----------+------------------+--------------+------+------+-------------+---------+------------+----------------------+\n","\n","\n","== Status ==\n","Current time: 2023-03-17 01:43:42 (running for 00:03:14.64)\n","Memory usage on this node: 3.7/12.7 GiB \n","Using AsyncHyperBand: num_stopped=0\n","Bracket: Iter 8.000: None | Iter 4.000: -1.6692905458450318 | Iter 2.000: -2.099749384880066 | Iter 1.000: -2.299063328170776\n","Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.39 GiB heap, 0.0/3.69 GiB objects\n","Result logdir: /root/ray_results/train_cifar_2023-03-17_01-40-28\n","Number of trials: 10/10 (9 PENDING, 1 RUNNING)\n","+-------------------------+----------+------------------+--------------+------+------+-------------+---------+------------+----------------------+\n","| Trial name              | status   | loc              |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n","|-------------------------+----------+------------------+--------------+------+------+-------------+---------+------------+----------------------|\n","| train_cifar_b22a4_00000 | RUNNING  | 172.28.0.12:4162 |           16 |   32 |   32 | 0.000414851 | 1.58192 |     0.4174 |                    5 |\n","| train_cifar_b22a4_00001 | PENDING  |                  |            8 |   16 |   32 | 0.0520736   |         |            |                      |\n","| train_cifar_b22a4_00002 | PENDING  |                  |            4 |   32 |    8 | 0.00498188  |         |            |                      |\n","| train_cifar_b22a4_00003 | PENDING  |                  |           16 |    8 |  128 | 0.00841198  |         |            |                      |\n","| train_cifar_b22a4_00004 | PENDING  |                  |            2 |  128 |    8 | 0.0115033   |         |            |                      |\n","| train_cifar_b22a4_00005 | PENDING  |                  |           16 |  256 |   64 | 0.000892888 |         |            |                      |\n","| train_cifar_b22a4_00006 | PENDING  |                  |            4 |   32 |  256 | 0.0251675   |         |            |                      |\n","| train_cifar_b22a4_00007 | PENDING  |                  |           16 |  256 |   64 | 0.000238698 |         |            |                      |\n","| train_cifar_b22a4_00008 | PENDING  |                  |            2 |  128 |  256 | 0.0198986   |         |            |                      |\n","| train_cifar_b22a4_00009 | PENDING  |                  |           16 |  128 |   64 | 0.000264479 |         |            |                      |\n","+-------------------------+----------+------------------+--------------+------+------+-------------+---------+------------+----------------------+\n","\n","\n","== Status ==\n","Current time: 2023-03-17 01:43:47 (running for 00:03:19.65)\n","Memory usage on this node: 3.7/12.7 GiB \n","Using AsyncHyperBand: num_stopped=0\n","Bracket: Iter 8.000: None | Iter 4.000: -1.6692905458450318 | Iter 2.000: -2.099749384880066 | Iter 1.000: -2.299063328170776\n","Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.39 GiB heap, 0.0/3.69 GiB objects\n","Result logdir: /root/ray_results/train_cifar_2023-03-17_01-40-28\n","Number of trials: 10/10 (9 PENDING, 1 RUNNING)\n","+-------------------------+----------+------------------+--------------+------+------+-------------+---------+------------+----------------------+\n","| Trial name              | status   | loc              |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n","|-------------------------+----------+------------------+--------------+------+------+-------------+---------+------------+----------------------|\n","| train_cifar_b22a4_00000 | RUNNING  | 172.28.0.12:4162 |           16 |   32 |   32 | 0.000414851 | 1.58192 |     0.4174 |                    5 |\n","| train_cifar_b22a4_00001 | PENDING  |                  |            8 |   16 |   32 | 0.0520736   |         |            |                      |\n","| train_cifar_b22a4_00002 | PENDING  |                  |            4 |   32 |    8 | 0.00498188  |         |            |                      |\n","| train_cifar_b22a4_00003 | PENDING  |                  |           16 |    8 |  128 | 0.00841198  |         |            |                      |\n","| train_cifar_b22a4_00004 | PENDING  |                  |            2 |  128 |    8 | 0.0115033   |         |            |                      |\n","| train_cifar_b22a4_00005 | PENDING  |                  |           16 |  256 |   64 | 0.000892888 |         |            |                      |\n","| train_cifar_b22a4_00006 | PENDING  |                  |            4 |   32 |  256 | 0.0251675   |         |            |                      |\n","| train_cifar_b22a4_00007 | PENDING  |                  |           16 |  256 |   64 | 0.000238698 |         |            |                      |\n","| train_cifar_b22a4_00008 | PENDING  |                  |            2 |  128 |  256 | 0.0198986   |         |            |                      |\n","| train_cifar_b22a4_00009 | PENDING  |                  |           16 |  128 |   64 | 0.000264479 |         |            |                      |\n","+-------------------------+----------+------------------+--------------+------+------+-------------+---------+------------+----------------------+\n","\n","\n","\u001b[2m\u001b[36m(func pid=4162)\u001b[0m [6,  2000] loss: 1.546\n","== Status ==\n","Current time: 2023-03-17 01:43:52 (running for 00:03:24.66)\n","Memory usage on this node: 3.6/12.7 GiB \n","Using AsyncHyperBand: num_stopped=0\n","Bracket: Iter 8.000: None | Iter 4.000: -1.6692905458450318 | Iter 2.000: -2.099749384880066 | Iter 1.000: -2.299063328170776\n","Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.39 GiB heap, 0.0/3.69 GiB objects\n","Result logdir: /root/ray_results/train_cifar_2023-03-17_01-40-28\n","Number of trials: 10/10 (9 PENDING, 1 RUNNING)\n","+-------------------------+----------+------------------+--------------+------+------+-------------+---------+------------+----------------------+\n","| Trial name              | status   | loc              |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n","|-------------------------+----------+------------------+--------------+------+------+-------------+---------+------------+----------------------|\n","| train_cifar_b22a4_00000 | RUNNING  | 172.28.0.12:4162 |           16 |   32 |   32 | 0.000414851 | 1.58192 |     0.4174 |                    5 |\n","| train_cifar_b22a4_00001 | PENDING  |                  |            8 |   16 |   32 | 0.0520736   |         |            |                      |\n","| train_cifar_b22a4_00002 | PENDING  |                  |            4 |   32 |    8 | 0.00498188  |         |            |                      |\n","| train_cifar_b22a4_00003 | PENDING  |                  |           16 |    8 |  128 | 0.00841198  |         |            |                      |\n","| train_cifar_b22a4_00004 | PENDING  |                  |            2 |  128 |    8 | 0.0115033   |         |            |                      |\n","| train_cifar_b22a4_00005 | PENDING  |                  |           16 |  256 |   64 | 0.000892888 |         |            |                      |\n","| train_cifar_b22a4_00006 | PENDING  |                  |            4 |   32 |  256 | 0.0251675   |         |            |                      |\n","| train_cifar_b22a4_00007 | PENDING  |                  |           16 |  256 |   64 | 0.000238698 |         |            |                      |\n","| train_cifar_b22a4_00008 | PENDING  |                  |            2 |  128 |  256 | 0.0198986   |         |            |                      |\n","| train_cifar_b22a4_00009 | PENDING  |                  |           16 |  128 |   64 | 0.000264479 |         |            |                      |\n","+-------------------------+----------+------------------+--------------+------+------+-------------+---------+------------+----------------------+\n","\n","\n","== Status ==\n","Current time: 2023-03-17 01:43:58 (running for 00:03:29.68)\n","Memory usage on this node: 3.7/12.7 GiB \n","Using AsyncHyperBand: num_stopped=0\n","Bracket: Iter 8.000: None | Iter 4.000: -1.6692905458450318 | Iter 2.000: -2.099749384880066 | Iter 1.000: -2.299063328170776\n","Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.39 GiB heap, 0.0/3.69 GiB objects\n","Result logdir: /root/ray_results/train_cifar_2023-03-17_01-40-28\n","Number of trials: 10/10 (9 PENDING, 1 RUNNING)\n","+-------------------------+----------+------------------+--------------+------+------+-------------+---------+------------+----------------------+\n","| Trial name              | status   | loc              |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n","|-------------------------+----------+------------------+--------------+------+------+-------------+---------+------------+----------------------|\n","| train_cifar_b22a4_00000 | RUNNING  | 172.28.0.12:4162 |           16 |   32 |   32 | 0.000414851 | 1.58192 |     0.4174 |                    5 |\n","| train_cifar_b22a4_00001 | PENDING  |                  |            8 |   16 |   32 | 0.0520736   |         |            |                      |\n","| train_cifar_b22a4_00002 | PENDING  |                  |            4 |   32 |    8 | 0.00498188  |         |            |                      |\n","| train_cifar_b22a4_00003 | PENDING  |                  |           16 |    8 |  128 | 0.00841198  |         |            |                      |\n","| train_cifar_b22a4_00004 | PENDING  |                  |            2 |  128 |    8 | 0.0115033   |         |            |                      |\n","| train_cifar_b22a4_00005 | PENDING  |                  |           16 |  256 |   64 | 0.000892888 |         |            |                      |\n","| train_cifar_b22a4_00006 | PENDING  |                  |            4 |   32 |  256 | 0.0251675   |         |            |                      |\n","| train_cifar_b22a4_00007 | PENDING  |                  |           16 |  256 |   64 | 0.000238698 |         |            |                      |\n","| train_cifar_b22a4_00008 | PENDING  |                  |            2 |  128 |  256 | 0.0198986   |         |            |                      |\n","| train_cifar_b22a4_00009 | PENDING  |                  |           16 |  128 |   64 | 0.000264479 |         |            |                      |\n","+-------------------------+----------+------------------+--------------+------+------+-------------+---------+------------+----------------------+\n","\n","\n","== Status ==\n","Current time: 2023-03-17 01:44:04 (running for 00:03:36.50)\n","Memory usage on this node: 3.7/12.7 GiB \n","Using AsyncHyperBand: num_stopped=0\n","Bracket: Iter 8.000: None | Iter 4.000: -1.6692905458450318 | Iter 2.000: -2.099749384880066 | Iter 1.000: -2.299063328170776\n","Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.39 GiB heap, 0.0/3.69 GiB objects\n","Result logdir: /root/ray_results/train_cifar_2023-03-17_01-40-28\n","Number of trials: 10/10 (9 PENDING, 1 RUNNING)\n","+-------------------------+----------+------------------+--------------+------+------+-------------+---------+------------+----------------------+\n","| Trial name              | status   | loc              |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n","|-------------------------+----------+------------------+--------------+------+------+-------------+---------+------------+----------------------|\n","| train_cifar_b22a4_00000 | RUNNING  | 172.28.0.12:4162 |           16 |   32 |   32 | 0.000414851 | 1.49463 |     0.4578 |                    6 |\n","| train_cifar_b22a4_00001 | PENDING  |                  |            8 |   16 |   32 | 0.0520736   |         |            |                      |\n","| train_cifar_b22a4_00002 | PENDING  |                  |            4 |   32 |    8 | 0.00498188  |         |            |                      |\n","| train_cifar_b22a4_00003 | PENDING  |                  |           16 |    8 |  128 | 0.00841198  |         |            |                      |\n","| train_cifar_b22a4_00004 | PENDING  |                  |            2 |  128 |    8 | 0.0115033   |         |            |                      |\n","| train_cifar_b22a4_00005 | PENDING  |                  |           16 |  256 |   64 | 0.000892888 |         |            |                      |\n","| train_cifar_b22a4_00006 | PENDING  |                  |            4 |   32 |  256 | 0.0251675   |         |            |                      |\n","| train_cifar_b22a4_00007 | PENDING  |                  |           16 |  256 |   64 | 0.000238698 |         |            |                      |\n","| train_cifar_b22a4_00008 | PENDING  |                  |            2 |  128 |  256 | 0.0198986   |         |            |                      |\n","| train_cifar_b22a4_00009 | PENDING  |                  |           16 |  128 |   64 | 0.000264479 |         |            |                      |\n","+-------------------------+----------+------------------+--------------+------+------+-------------+---------+------------+----------------------+\n","\n","\n","== Status ==\n","Current time: 2023-03-17 01:44:09 (running for 00:03:41.51)\n","Memory usage on this node: 3.7/12.7 GiB \n","Using AsyncHyperBand: num_stopped=0\n","Bracket: Iter 8.000: None | Iter 4.000: -1.6692905458450318 | Iter 2.000: -2.099749384880066 | Iter 1.000: -2.299063328170776\n","Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.39 GiB heap, 0.0/3.69 GiB objects\n","Result logdir: /root/ray_results/train_cifar_2023-03-17_01-40-28\n","Number of trials: 10/10 (9 PENDING, 1 RUNNING)\n","+-------------------------+----------+------------------+--------------+------+------+-------------+---------+------------+----------------------+\n","| Trial name              | status   | loc              |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n","|-------------------------+----------+------------------+--------------+------+------+-------------+---------+------------+----------------------|\n","| train_cifar_b22a4_00000 | RUNNING  | 172.28.0.12:4162 |           16 |   32 |   32 | 0.000414851 | 1.49463 |     0.4578 |                    6 |\n","| train_cifar_b22a4_00001 | PENDING  |                  |            8 |   16 |   32 | 0.0520736   |         |            |                      |\n","| train_cifar_b22a4_00002 | PENDING  |                  |            4 |   32 |    8 | 0.00498188  |         |            |                      |\n","| train_cifar_b22a4_00003 | PENDING  |                  |           16 |    8 |  128 | 0.00841198  |         |            |                      |\n","| train_cifar_b22a4_00004 | PENDING  |                  |            2 |  128 |    8 | 0.0115033   |         |            |                      |\n","| train_cifar_b22a4_00005 | PENDING  |                  |           16 |  256 |   64 | 0.000892888 |         |            |                      |\n","| train_cifar_b22a4_00006 | PENDING  |                  |            4 |   32 |  256 | 0.0251675   |         |            |                      |\n","| train_cifar_b22a4_00007 | PENDING  |                  |           16 |  256 |   64 | 0.000238698 |         |            |                      |\n","| train_cifar_b22a4_00008 | PENDING  |                  |            2 |  128 |  256 | 0.0198986   |         |            |                      |\n","| train_cifar_b22a4_00009 | PENDING  |                  |           16 |  128 |   64 | 0.000264479 |         |            |                      |\n","+-------------------------+----------+------------------+--------------+------+------+-------------+---------+------------+----------------------+\n","\n","\n","== Status ==\n","Current time: 2023-03-17 01:44:14 (running for 00:03:46.54)\n","Memory usage on this node: 3.7/12.7 GiB \n","Using AsyncHyperBand: num_stopped=0\n","Bracket: Iter 8.000: None | Iter 4.000: -1.6692905458450318 | Iter 2.000: -2.099749384880066 | Iter 1.000: -2.299063328170776\n","Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.39 GiB heap, 0.0/3.69 GiB objects\n","Result logdir: /root/ray_results/train_cifar_2023-03-17_01-40-28\n","Number of trials: 10/10 (9 PENDING, 1 RUNNING)\n","+-------------------------+----------+------------------+--------------+------+------+-------------+---------+------------+----------------------+\n","| Trial name              | status   | loc              |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n","|-------------------------+----------+------------------+--------------+------+------+-------------+---------+------------+----------------------|\n","| train_cifar_b22a4_00000 | RUNNING  | 172.28.0.12:4162 |           16 |   32 |   32 | 0.000414851 | 1.49463 |     0.4578 |                    6 |\n","| train_cifar_b22a4_00001 | PENDING  |                  |            8 |   16 |   32 | 0.0520736   |         |            |                      |\n","| train_cifar_b22a4_00002 | PENDING  |                  |            4 |   32 |    8 | 0.00498188  |         |            |                      |\n","| train_cifar_b22a4_00003 | PENDING  |                  |           16 |    8 |  128 | 0.00841198  |         |            |                      |\n","| train_cifar_b22a4_00004 | PENDING  |                  |            2 |  128 |    8 | 0.0115033   |         |            |                      |\n","| train_cifar_b22a4_00005 | PENDING  |                  |           16 |  256 |   64 | 0.000892888 |         |            |                      |\n","| train_cifar_b22a4_00006 | PENDING  |                  |            4 |   32 |  256 | 0.0251675   |         |            |                      |\n","| train_cifar_b22a4_00007 | PENDING  |                  |           16 |  256 |   64 | 0.000238698 |         |            |                      |\n","| train_cifar_b22a4_00008 | PENDING  |                  |            2 |  128 |  256 | 0.0198986   |         |            |                      |\n","| train_cifar_b22a4_00009 | PENDING  |                  |           16 |  128 |   64 | 0.000264479 |         |            |                      |\n","+-------------------------+----------+------------------+--------------+------+------+-------------+---------+------------+----------------------+\n","\n","\n","== Status ==\n","Current time: 2023-03-17 01:44:19 (running for 00:03:51.56)\n","Memory usage on this node: 3.7/12.7 GiB \n","Using AsyncHyperBand: num_stopped=0\n","Bracket: Iter 8.000: None | Iter 4.000: -1.6692905458450318 | Iter 2.000: -2.099749384880066 | Iter 1.000: -2.299063328170776\n","Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.39 GiB heap, 0.0/3.69 GiB objects\n","Result logdir: /root/ray_results/train_cifar_2023-03-17_01-40-28\n","Number of trials: 10/10 (9 PENDING, 1 RUNNING)\n","+-------------------------+----------+------------------+--------------+------+------+-------------+---------+------------+----------------------+\n","| Trial name              | status   | loc              |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n","|-------------------------+----------+------------------+--------------+------+------+-------------+---------+------------+----------------------|\n","| train_cifar_b22a4_00000 | RUNNING  | 172.28.0.12:4162 |           16 |   32 |   32 | 0.000414851 | 1.49463 |     0.4578 |                    6 |\n","| train_cifar_b22a4_00001 | PENDING  |                  |            8 |   16 |   32 | 0.0520736   |         |            |                      |\n","| train_cifar_b22a4_00002 | PENDING  |                  |            4 |   32 |    8 | 0.00498188  |         |            |                      |\n","| train_cifar_b22a4_00003 | PENDING  |                  |           16 |    8 |  128 | 0.00841198  |         |            |                      |\n","| train_cifar_b22a4_00004 | PENDING  |                  |            2 |  128 |    8 | 0.0115033   |         |            |                      |\n","| train_cifar_b22a4_00005 | PENDING  |                  |           16 |  256 |   64 | 0.000892888 |         |            |                      |\n","| train_cifar_b22a4_00006 | PENDING  |                  |            4 |   32 |  256 | 0.0251675   |         |            |                      |\n","| train_cifar_b22a4_00007 | PENDING  |                  |           16 |  256 |   64 | 0.000238698 |         |            |                      |\n","| train_cifar_b22a4_00008 | PENDING  |                  |            2 |  128 |  256 | 0.0198986   |         |            |                      |\n","| train_cifar_b22a4_00009 | PENDING  |                  |           16 |  128 |   64 | 0.000264479 |         |            |                      |\n","+-------------------------+----------+------------------+--------------+------+------+-------------+---------+------------+----------------------+\n","\n","\n","\u001b[2m\u001b[36m(func pid=4162)\u001b[0m [7,  2000] loss: 1.489\n"]},{"output_type":"stream","name":"stderr","text":["2023-03-17 01:44:23,889\tWARNING tune.py:146 -- Stop signal received (e.g. via SIGINT/Ctrl+C), ending Ray Tune run. This will try to checkpoint the experiment state one last time. Press CTRL+C (or send SIGINT/SIGKILL/SIGTERM) to skip. \n","2023-03-17 01:44:24,922\tERROR tune.py:794 -- Trials did not complete: [train_cifar_b22a4_00000, train_cifar_b22a4_00001, train_cifar_b22a4_00002, train_cifar_b22a4_00003, train_cifar_b22a4_00004, train_cifar_b22a4_00005, train_cifar_b22a4_00006, train_cifar_b22a4_00007, train_cifar_b22a4_00008, train_cifar_b22a4_00009]\n","2023-03-17 01:44:24,930\tINFO tune.py:798 -- Total run time: 236.62 seconds (236.57 seconds for the tuning loop).\n","2023-03-17 01:44:24,932\tWARNING tune.py:804 -- Experiment has been interrupted, but the most recent state was saved. You can continue running this experiment by passing `resume=True` to `tune.run()`\n"]},{"output_type":"stream","name":"stdout","text":["== Status ==\n","Current time: 2023-03-17 01:44:24 (running for 00:03:56.57)\n","Memory usage on this node: 3.7/12.7 GiB \n","Using AsyncHyperBand: num_stopped=0\n","Bracket: Iter 8.000: None | Iter 4.000: -1.6692905458450318 | Iter 2.000: -2.099749384880066 | Iter 1.000: -2.299063328170776\n","Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.39 GiB heap, 0.0/3.69 GiB objects\n","Result logdir: /root/ray_results/train_cifar_2023-03-17_01-40-28\n","Number of trials: 10/10 (9 PENDING, 1 RUNNING)\n","+-------------------------+----------+------------------+--------------+------+------+-------------+---------+------------+----------------------+\n","| Trial name              | status   | loc              |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n","|-------------------------+----------+------------------+--------------+------+------+-------------+---------+------------+----------------------|\n","| train_cifar_b22a4_00000 | RUNNING  | 172.28.0.12:4162 |           16 |   32 |   32 | 0.000414851 | 1.49463 |     0.4578 |                    6 |\n","| train_cifar_b22a4_00001 | PENDING  |                  |            8 |   16 |   32 | 0.0520736   |         |            |                      |\n","| train_cifar_b22a4_00002 | PENDING  |                  |            4 |   32 |    8 | 0.00498188  |         |            |                      |\n","| train_cifar_b22a4_00003 | PENDING  |                  |           16 |    8 |  128 | 0.00841198  |         |            |                      |\n","| train_cifar_b22a4_00004 | PENDING  |                  |            2 |  128 |    8 | 0.0115033   |         |            |                      |\n","| train_cifar_b22a4_00005 | PENDING  |                  |           16 |  256 |   64 | 0.000892888 |         |            |                      |\n","| train_cifar_b22a4_00006 | PENDING  |                  |            4 |   32 |  256 | 0.0251675   |         |            |                      |\n","| train_cifar_b22a4_00007 | PENDING  |                  |           16 |  256 |   64 | 0.000238698 |         |            |                      |\n","| train_cifar_b22a4_00008 | PENDING  |                  |            2 |  128 |  256 | 0.0198986   |         |            |                      |\n","| train_cifar_b22a4_00009 | PENDING  |                  |           16 |  128 |   64 | 0.000264479 |         |            |                      |\n","+-------------------------+----------+------------------+--------------+------+------+-------------+---------+------------+----------------------+\n","\n","\n","== Status ==\n","Current time: 2023-03-17 01:44:24 (running for 00:03:56.58)\n","Memory usage on this node: 3.7/12.7 GiB \n","Using AsyncHyperBand: num_stopped=0\n","Bracket: Iter 8.000: None | Iter 4.000: -1.6692905458450318 | Iter 2.000: -2.099749384880066 | Iter 1.000: -2.299063328170776\n","Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.39 GiB heap, 0.0/3.69 GiB objects\n","Result logdir: /root/ray_results/train_cifar_2023-03-17_01-40-28\n","Number of trials: 10/10 (9 PENDING, 1 RUNNING)\n","+-------------------------+----------+------------------+--------------+------+------+-------------+---------+------------+----------------------+\n","| Trial name              | status   | loc              |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n","|-------------------------+----------+------------------+--------------+------+------+-------------+---------+------------+----------------------|\n","| train_cifar_b22a4_00000 | RUNNING  | 172.28.0.12:4162 |           16 |   32 |   32 | 0.000414851 | 1.49463 |     0.4578 |                    6 |\n","| train_cifar_b22a4_00001 | PENDING  |                  |            8 |   16 |   32 | 0.0520736   |         |            |                      |\n","| train_cifar_b22a4_00002 | PENDING  |                  |            4 |   32 |    8 | 0.00498188  |         |            |                      |\n","| train_cifar_b22a4_00003 | PENDING  |                  |           16 |    8 |  128 | 0.00841198  |         |            |                      |\n","| train_cifar_b22a4_00004 | PENDING  |                  |            2 |  128 |    8 | 0.0115033   |         |            |                      |\n","| train_cifar_b22a4_00005 | PENDING  |                  |           16 |  256 |   64 | 0.000892888 |         |            |                      |\n","| train_cifar_b22a4_00006 | PENDING  |                  |            4 |   32 |  256 | 0.0251675   |         |            |                      |\n","| train_cifar_b22a4_00007 | PENDING  |                  |           16 |  256 |   64 | 0.000238698 |         |            |                      |\n","| train_cifar_b22a4_00008 | PENDING  |                  |            2 |  128 |  256 | 0.0198986   |         |            |                      |\n","| train_cifar_b22a4_00009 | PENDING  |                  |           16 |  128 |   64 | 0.000264479 |         |            |                      |\n","+-------------------------+----------+------------------+--------------+------+------+-------------+---------+------------+----------------------+\n","\n","\n","Best trial config: {'l1': 32, 'l2': 32, 'lr': 0.0004148513922410307, 'batch_size': 16}\n","Best trial final validation loss: 1.4946309509277345\n","Best trial final validation accuracy: 0.4578\n"]},{"output_type":"error","ename":"AttributeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m<ipython-input-13-ee95b3e0a4d1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0;31m# You can change the number of GPUs per trial here:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0mwandb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"73a1afbee8c19ff574b3531adf3a4e0961d0fbc1\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_samples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_num_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgpus_per_trial\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-13-ee95b3e0a4d1>\u001b[0m in \u001b[0;36mmain\u001b[0;34m(num_samples, max_num_epochs, gpus_per_trial)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0mbest_trained_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m     \u001b[0mbest_checkpoint_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbest_trial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m     model_state, optimizer_state = torch.load(os.path.join(\n\u001b[1;32m     51\u001b[0m         best_checkpoint_dir, \"checkpoint\"))\n","\u001b[0;31mAttributeError\u001b[0m: '_TrackedCheckpoint' object has no attribute 'value'"]}],"source":["from ray.tune.suggest.bayesopt import BayesOptSearch\n","from ray.tune.suggest.hyperopt import HyperOptSearch\n","\n","def main(num_samples=10, max_num_epochs=10, gpus_per_trial=2):\n","    \n","    data_dir = os.path.abspath(\"./data\")\n","    load_data(data_dir)\n","    config = {\n","        \"l1\": tune.sample_from(lambda _: 2 ** np.random.randint(2, 9)),\n","        \"l2\": tune.sample_from(lambda _: 2 ** np.random.randint(2, 9)),\n","        \"lr\": tune.loguniform(1e-4, 1e-1),\n","        \"batch_size\": tune.choice([2, 4, 8, 16])\n","    }\n","    scheduler = ASHAScheduler(\n","        metric=\"loss\",\n","        mode=\"min\",\n","        max_t=max_num_epochs,\n","        grace_period=1,\n","        reduction_factor=2)\n","    reporter = CLIReporter(\n","        # parameter_columns=[\"l1\", \"l2\", \"lr\", \"batch_size\"],\n","        metric_columns=[\"loss\", \"accuracy\", \"training_iteration\"])\n","    \n","    # 실행\n","    result = tune.run( \n","        partial(train_cifar, data_dir=data_dir),\n","        resources_per_trial={\"cpu\": 2, \"gpu\": gpus_per_trial},\n","        config=config,\n","        num_samples=num_samples,\n","        scheduler=scheduler,\n","        progress_reporter=reporter)\n","\n","    # 가장 높은 성능의 trial 불러오기\n","    best_trial = result.get_best_trial(\"loss\", \"min\", \"last\")\n","    print(\"Best trial config: {}\".format(best_trial.config))\n","    print(\"Best trial final validation loss: {}\".format(\n","        best_trial.last_result[\"loss\"]))\n","    print(\"Best trial final validation accuracy: {}\".format(\n","        best_trial.last_result[\"accuracy\"]))\n","\n","    best_trained_model = Net(best_trial.config[\"l1\"], best_trial.config[\"l2\"])\n","    device = \"cpu\"\n","    if torch.cuda.is_available():\n","        device = \"cuda:0\"\n","        if gpus_per_trial > 1:\n","            best_trained_model = nn.DataParallel(best_trained_model)\n","    best_trained_model.to(device)\n","\n","    best_checkpoint_dir = best_trial.checkpoint.value\n","    model_state, optimizer_state = torch.load(os.path.join(\n","        best_checkpoint_dir, \"checkpoint\"))\n","    best_trained_model.load_state_dict(model_state)\n","\n","    test_acc = test_accuracy(best_trained_model, device)\n","    print(\"Best trial test set accuracy: {}\".format(test_acc))\n","\n","\n","if __name__ == \"__main__\":\n","    # You can change the number of GPUs per trial here:\n","    wandb.login(key=\"73a1afbee8c19ff574b3531adf3a4e0961d0fbc1\")\n","    main(num_samples=10, max_num_epochs=10, gpus_per_trial=0)"]},{"cell_type":"markdown","source":["## Further Question\n","1. 모델의 모든 layer에서 learning rate가 항상 같아야 할까요? 같이 논의해보세요!\n","  - 달라도 된다..! fine-tuning 할때!\n","2. ray tune을 이용해 hyperparameter 탐색을 하려고 합니다. 아직 어떤 hyperparmeter도 탐색한적이 없지만 시간이 없어서 1개의 hyperparameter만 탐색할 수 있다면 어떤 hyperparameter를 선택할 것 같나요? 같이 논의해보세요!\n","  - learning rate가 가장 중요함\n","  - 그 다음으로 hidden unit의 개수, mini-batch의 크기, 모멘텀 값\n","  - 그 다음으로 layer의 수 등.."],"metadata":{"id":"KEhbrUssPbsB"}},{"cell_type":"markdown","source":["## 회고\n","- hyperparameter 튜닝을 통해 향상되는 효과는 미미하다...튜닝보다 데이터 하나하나가 훨씬 중요하다!\n","- 성능을 올릴 목적보다는 모델을 가볍게 만드는 목적으로 쓰자"],"metadata":{"id":"pAQTXo_WOpSX"}}],"metadata":{"accelerator":"GPU","colab":{"provenance":[{"file_id":"1RthQAG9fToB2lBYsTMlcFrWaRPrc_rbI","timestamp":1679014953450}]},"kernelspec":{"display_name":"Lablup FF 20.07 on Python 3.6 (CUDA 10.1)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.9"}},"nbformat":4,"nbformat_minor":0}
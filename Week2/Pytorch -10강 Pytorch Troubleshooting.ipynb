{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOd8Rxs/okq8tSUYr5Nh0uT"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["## OOM(Out Of Memory Error)가 해결하기 어려운 이유\n","- 발생 이유를 찾기 어려움\n","- 발생 근원지 찾기 어려움\n","- Error backtraking이 이상한데로...\n","- 메모리의 이전상황 파악이 어려움\n","\n","- 보통의 해결 방법: 배치사이즈 줄이기 → GPU clean → Run!"],"metadata":{"id":"diQgpzcERajt"}},{"cell_type":"markdown","source":["### 해결방법1. GPUUtill 사용하기\n","- nvidia-smi처럼 GPU 상태 보여주는 모듈\n","- iter마다 메모리가 늘어나는지 확인\n","- colab에서 주로 사용\n","\n","```\n","!pip insatll GPUtil\n","import GPUtil\n","GPUtil.showUtilization()\n","```\n","\n"],"metadata":{"id":"F3wLwF90SEfm"}},{"cell_type":"markdown","source":["### 해결방법2. torch.cuda.empty_cache()\n","- backward pass 데이터 쌓인 것 없앨 때 사용\n","- 사용되지 않은 GPU상 cache 정리\n","- 가용 메모리 확보\n","- del(memory free)과는 다름\n","- reset 대신 쓰기 좋은 함수\n","\n","\n","```\n","import torch\n","from GPUtil import showUtilization as gpu_usage\n","print(\"Initial GPU Usage\")\n","gpu_usage()\n","tensorList = []\n","# 랜덤값을 cuda gpu에 쌓이게 함\n","for x in range(10):\n","  tensorList.append(torch.randn(10000000,10).cuda())\n","print(\"GPU Usage after emptying the cache\")\n","torch.cuda.empty_cache()\n","gpu_usage()\n","```\n","\n"],"metadata":{"id":"lFJ0YAtRSmvS"}},{"cell_type":"markdown","source":["### 해결방법3. trainning loop에 tensor로 축적되는 변수 확인\n","- tensor로 처리된 변수는 GPU 상의 메모리 사용\n","- loop안에 연산에 있을 때 GPU에 computational graph 생성\n","\n","- 1-d tensor의 경우 파이썬 기본 객체로 변환하여 처리 (.item, float)\n","\n","  ```\n","  total_loss=0\n","  for x in range(10):\n","    # assume loss is computed\n","    iter_loss = torch.randn(3,4).mean()\n","    iter_loss.requires_grad = True\n","    total_loss += iter_loss.item()\n","  ```\n","\n"],"metadata":{"id":"HYdtjEgpT0vg"}},{"cell_type":"markdown","source":["### 해결방법4. del 명령어 적절히 사용하기\n","- 필요가 없어진 변수는 적절한 삭제가 필요\n","- 파이썬은 메모리 배치 특성상 loop이 끝나도 메모리를 차지함\n","- loop 나가기 전에 del 해주기\n"],"metadata":{"id":"kr3EuAJSUp54"}},{"cell_type":"markdown","source":["### 해결방법5. 가능한 batch 사이즈 실험해보기\n","- batch 사이즈를 1로 해서 실험해보기\n","- 코드가 정갈해짐\n","\n","\n","```\n","oom = False\n","try:\n","    run_model(batch_size)\n","except RuntimeError: # Out of memory\n","    oom = True\n","if oom:\n","    for _ in range(batch_size):\n","        run_model(1)\n","```\n","\n"],"metadata":{"id":"3cbHAttaU-QO"}},{"cell_type":"markdown","source":["### 해결방법6. torch.no_grad() 사용\n","- inference 시점에서는 torch.no_grad() 사용\n","- <backward pass로 인해 쌓이는 메모리>가 안생김"],"metadata":{"id":"0sJNMKvHVOdg"}},{"cell_type":"markdown","source":["## 이외...\n","-  CUDNN_STATUS_NOT_INIT: GPU 문제..\n","- device-side-asser: OOM과 비슷\n","- 적절한 코드 처리가 필요!"],"metadata":{"id":"8vENH26nVjI7"}},{"cell_type":"markdown","source":["## 기본적으로 주의해야할 것\n","- colab에서 너무 큰 사이즈는 실행하지 말 것\n","  - ex. linear, CNN, LSTM\n","- CNN의 대부분의 에러는 크기가 안 맞아서 생김\n","  - torchsummary로 사이즈 맞추기\n","- tensor의 float precision을 16bit로 줄일수 있음"],"metadata":{"id":"sE_K3sPPVxg2"}}]}